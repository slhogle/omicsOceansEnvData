[
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "Retrieve, format, and impute Tara Oceans environmental data",
    "section": "1.1 ATTRIBUTION",
    "text": "1.1 ATTRIBUTION\nPlease only download and use data if you agree to respective license terms for each data source!\nIf you use any of the data mentioned or described in this repository it is ESSENTIAL!! that you properly cite the data sources. These include (but are not limited to):\n\n1.1.1 Longhurst codes, identifiers, and descriptions\nLonghurst, A. R. 1998. Ecological Geography of the Sea, Academic Press.\nhttps://github.com/slhogle/Longhurst-Province-Finder\n\n\n1.1.2 Prochlorococcus ecotype abundances from metagenomes\nBecker, J. W., S. L. Hogle, K. Rosendo, and S. W. Chisholm. 2019. Co-culture and biogeography of Prochlorococcus and SAR11. ISME J. doi:10.1038/s41396-019-0365-4\n\n\n1.1.3 MIT DARWIN Model output\nSimons Collaborative Marine Atlas project (CMAP) https://simonscmap.com/\nDutkiewicz, S., A.E. Hickman, O. Jahn, W.W. Gregg, C.B. Mouw, and M.J. Follows, 2015: Capturing optically important constituents and properties in a marine biogeochemical and ecosystem model. Biogeoscience, 12, 4447-4481 doi:10.5194/bg-12-4447-2015, https://doi.org/10.5194/bg-12-4447-2015\nForget, G., Campin, J.-M., Heimbach, P., Hill, C. N., Ponte, R. M., and Wunsch, C.: ECCO version 4: an integrated framework for non-linear inverse modeling and global ocean state estimation, Geosci. Model Dev., 8, 3071-3104, https://doi.org/10.5194/gmd-8-3071-2015, 2015\nForget, G., D. Ferreira, and X. Liang, 2015: On the observability of turbulent transport rates by argo: supporting evidence from an inversion experiment. Ocean Science, 11, 839–853, doi:10.5194/os-11-839-2015\nForget, G. and R. Ponte, 2015: The partition of regional sea level variability. Progress in Oceanography, 137, 173–195, https://doi.org/10.1016/j.pocean.2015.06.002\nForget, G., 2018: Initial, preliminary version of the CBIOMES-global model setup and documentation (Version v0.0.1). Zenodo. http://doi.org/10.5281/zenodo.1343303\nForget, G., 2019: Update MITgcm & DarwinProject elements (Version v0.1.0). Zenodo. http://doi.org/10.5281/zenodo.2653669 Ward, B.A., S. Dutkiewicz, O. Jahn, and M.J. Follows, 2012: A size-structured food-web model for the global ocean. Limnol. Oceanogr., 57, 1877-1891. https://aslopubs.onlinelibrary.wiley.com/doi/abs/10.4319/lo.2012.57.6.1877\n\n\n1.1.4 Tara Oceans datasets\nSunagawa, S., L. P. Coelho, S. Chaffron, and others. 2015. Structure and function of the global ocean microbiome. Science 348: 1261359.\nGuidi, Lionel; Picheral, Marc; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about sensor data in the targeted environmental feature. PANGAEA, https://doi.org/10.1594/PANGAEA.875576"
  },
  {
    "objectID": "R/01_download_data.html",
    "href": "R/01_download_data.html",
    "title": "Download TARA Oceans environmental data",
    "section": "",
    "text": "Citation:\nNote that the data sets zip bundled at https://doi.pangaea.de/10.1594/PANGAEA.875582 (above reference) are data sets Section 2.5, Section 2.6, Section 2.7 in the sections below.\nThis environmental data is not subset or filtered in any way. It comes directly from the Pangaea so the user will need to perform subsequent filtering/subsetting to ensure the data matches their sequencing samples.",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#sequencing-library-information-pangaea.875581",
    "href": "R/01_download_data.html#sequencing-library-information-pangaea.875581",
    "title": "Download TARA Oceans environmental data",
    "section": "2.1 Sequencing library information (PANGAEA.875581)",
    "text": "2.1 Sequencing library information (PANGAEA.875581)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875581\nCitation:\n\nAlberti, Adriana; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Methodology used in the lab for molecular analyses and links to the Sequence Read Archive of selected samples from the Tara Oceans Expedition (2009-2013) [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875581, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_SEQUENCING_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875581 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 19) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;% \n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_frac_low = 10,\n                size_frac_high = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875581_', stringr::str_pad(15:24, side = \"left\", pad = \"0\", width = 2)))\n\n# save for later\nreadr::write_rds(PANGAEA_875581, here::here(\"_data_raw\", \"PANGAEA_875581.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875581_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#carbonate-chemistry-pangaea.875567",
    "href": "R/01_download_data.html#carbonate-chemistry-pangaea.875567",
    "title": "Download TARA Oceans environmental data",
    "section": "2.2 Carbonate chemistry (PANGAEA.875567)",
    "text": "2.2 Carbonate chemistry (PANGAEA.875567)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875567\nCitation:\n\nGuidi, Lionel; Gattuso, Jean-Pierre; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about carbonate chemistry in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875567, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_ENV-DEPTH-CARB_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875567 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 21) %&gt;% \n  # for setting column types. For some reason I can't maket his work within readxl\n  # https://github.com/tidyverse/readxl/issues/198\n  mutate(across(19:last_col(), as.numeric)) %&gt;% \n  mutate(across(19:last_col(), ~ifelse(is.nan(.), NA, .))) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;%\n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_frac_low = 10,\n                size_frac_high = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875567_', str_pad(15:68, side = \"left\", pad = \"0\", width = 2)))\n\n# save for later\nreadr::write_rds(PANGAEA_875567, here::here(\"_data_raw\", \"PANGAEA_875567.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875567_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#nutrient-concentrations-pangaea.875575",
    "href": "R/01_download_data.html#nutrient-concentrations-pangaea.875575",
    "title": "Download TARA Oceans environmental data",
    "section": "2.3 Nutrient concentrations (PANGAEA.875575)",
    "text": "2.3 Nutrient concentrations (PANGAEA.875575)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875575\nCitation:\n\nGuidi, Lionel; Morin, Pascal; Coppola, Laurent; Tremblay, Jean-Éric; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about nutrients in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875575, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_ENV-DEPTH-NUT_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875575 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 21)  %&gt;% \n  # for setting column types. For some reason I can't maket his work within readxl\n  # https://github.com/tidyverse/readxl/issues/198\n  mutate(across(19:last_col(), as.numeric)) %&gt;% \n  mutate(across(19:last_col(), ~ifelse(is.nan(.), NA, .))) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;%\n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_frac_low = 10,\n                size_frac_high = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875575_', str_pad(15:38, side = \"left\", pad = \"0\", width = 2)))\n\n# save for later\nreadr::write_rds(PANGAEA_875575, here::here(\"_data_raw\", \"PANGAEA_875575.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875575_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#pigment-concentrations-pangaea.875569",
    "href": "R/01_download_data.html#pigment-concentrations-pangaea.875569",
    "title": "Download TARA Oceans environmental data",
    "section": "2.4 Pigment concentrations (PANGAEA.875569)",
    "text": "2.4 Pigment concentrations (PANGAEA.875569)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875569\nCitation:\n\nGuidi, Lionel; Ras, Josephine; Claustre, Hervé; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about pigment concentrations (HPLC) in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875569, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_ENV-DEPTH-HPLC_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875569 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 21) %&gt;% \n  # for setting column types. For some reason I can't maket his work within readxl\n  # https://github.com/tidyverse/readxl/issues/198\n  mutate(across(19:last_col(), as.numeric)) %&gt;% \n  mutate(across(19:last_col(), ~ifelse(is.nan(.), NA, .))) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;% \n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_frac_low = 10,\n                size_frac_high = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875569_', str_pad(15:143, side = \"left\", pad = \"0\", width = 2)))\n\n# save for later\nreadr::write_rds(PANGAEA_875569, here::here(\"_data_raw\", \"PANGAEA_875569.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875569_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#sec-PANGAEA.875576",
    "href": "R/01_download_data.html#sec-PANGAEA.875576",
    "title": "Download TARA Oceans environmental data",
    "section": "2.5 Sensor data (PANGAEA.875576)",
    "text": "2.5 Sensor data (PANGAEA.875576)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875576\nCitation:\n\nGuidi, Lionel; Picheral, Marc; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about sensor data in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875576, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# download the file\ndownload.file(\"https://doi.pangaea.de/10.1594/PANGAEA.875576?format=textfile\", \n              tmpdir, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\n# this is annoying. The pangeae text files have a bunch of metadata headers between the characters\n#/* */ and but I couldn't immediately think of a way to parse a that in readr so I just grepped \"*/\"\n# which basically means we must read the file twice and take the performance hit. Also this may be \n# brittle in a way that I can't anticipate right now\nskipline &lt;- grep('\\\\*/', readLines(tmpdir))\n\nPANGAEA_875576 &lt;- read_tsv(tmpdir, skip = skipline) %&gt;% \n  mutate(across(13:15, as.numeric)) %&gt;% \n  mutate(across(24:last_col(), as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_basis = 4, \n                tara_campaign = 5, \n                tara_station = 6,\n                sampling_device = 7, \n                tara_event = 8, \n                date_time = 9,\n                latitude = 10,\n                longitude = 11,\n                env_ontology = 12,\n                depth = 13,\n                depth_min = 14, \n                depth_max = 15,\n                size_frac_low = 16,\n                size_frac_high = 17,\n                tara_id01 = 18,\n                tara_id02 = 19,\n                tara_id03 = 20) %&gt;%\n  mutate(date_time = lubridate::ymd_hms(date_time)) %&gt;% \n  dplyr::rename_with(.cols = 21:last_col(), ~ stringr::str_c('PANGAEA.875576_', str_pad(21:147, side = \"left\", pad = \"0\", width = 2)))\n\n# save the data for reuse\nreadr::write_rds(PANGAEA_875576, here::here(\"_data_raw\", \"PANGAEA_875576.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::file_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875576_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#sec-PANGAEA.875577",
    "href": "R/01_download_data.html#sec-PANGAEA.875577",
    "title": "Download TARA Oceans environmental data",
    "section": "2.6 Derived mesoscale features (PANGAEA.875577)",
    "text": "2.6 Derived mesoscale features (PANGAEA.875577)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875577\nCitation:\n\nArdyna, Mathieu; d’Ovidio, Francesco; Speich, Sabrina; Leconte, Jade; Chaffron, Samuel; Audic, Stephane; Garczarek, Laurence; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about mesoscale features at the sampling location [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875577, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\nNote most of these features seem to be derived from model or satellite data and do not represent in situ measurements.\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# download the file\ndownload.file(\"https://doi.pangaea.de/10.1594/PANGAEA.875577?format=textfile\", \n              tmpdir, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\n# this is annoying. The pangeae text files have a bunch of metadata headers between the characters\n#/* */ and but I couldn't immediately think of a way to parse a that in readr so I just grepped \"*/\"\n# which basically means we must read the file twice and take the performance hit. Also this may be \n# brittle in a way that I can't anticipate right now\nskipline &lt;- grep('\\\\*/', readLines(tmpdir))\n\nPANGAEA_875577 &lt;- read_tsv(tmpdir, skip = skipline) %&gt;% \n  mutate(across(13:15, as.numeric)) %&gt;% \n  mutate(across(24:last_col(), as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_basis = 4, \n                tara_campaign = 5, \n                tara_station = 6,\n                sampling_device = 7, \n                tara_event = 8, \n                date_time = 9,\n                latitude = 10,\n                longitude = 11,\n                env_ontology = 12,\n                depth = 13,\n                depth_min = 14,\n                depth_max = 15,\n                size_frac_low = 16,\n                size_frac_high = 17,\n                tara_id01 = 18,\n                tara_id02 = 19,\n                tara_id03 = 20) %&gt;%\n  mutate(date_time = lubridate::ymd_hms(date_time)) %&gt;% \n  dplyr::rename_with(.cols = 21:last_col(), ~ stringr::str_c('PANGAEA.875577_', str_pad(21:71, side = \"left\", pad = \"0\", width = 2)))\n\n# save the data for reuse\nreadr::write_rds(PANGAEA_875577, here::here(\"_data_raw\", \"PANGAEA_875577.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::file_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875577_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "R/01_download_data.html#sec-PANGAEA.875579",
    "href": "R/01_download_data.html#sec-PANGAEA.875579",
    "title": "Download TARA Oceans environmental data",
    "section": "2.7 Whole water column features (PANGAEA.875579)",
    "text": "2.7 Whole water column features (PANGAEA.875579)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875579\nCitation:\n\nSpeich, Sabrina; Chaffron, Samuel; Ardyna, Mathieu; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about the water column features at the sampling location [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875579, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\nThese features seem to contain information about specific features in the water column like the DCM, primary nitrite maximum, and the depth of the O2 minimum.\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# download the file\ndownload.file(\"https://doi.pangaea.de/10.1594/PANGAEA.875579?format=textfile\", \n              tmpdir, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\n# this is annoying. The Pangaea text files have a bunch of metadata headers between the characters\n#/* */ and but I couldn't immediately think of a way to parse a that in readr so I just grepped \"*/\"\n# which basically means we must read the file twice and take the performance hit. Also this may be \n# brittle in a way that I can't anticipate right now\nskipline &lt;- grep('\\\\*/', readLines(tmpdir))\n\nPANGAEA_875579 &lt;- read_tsv(tmpdir, skip = skipline) %&gt;% \n  mutate(across(13:15, as.numeric)) %&gt;% \n  mutate(across(33:last_col(), as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_basis = 4, \n                tara_campaign = 5, \n                tara_station = 6,\n                sampling_device = 7, \n                tara_event = 8, \n                date_time = 9,\n                latitude = 10,\n                longitude = 11,\n                env_ontology = 12,\n                depth = 13,\n                depth_min = 14,\n                depth_max = 15,\n                size_frac_low = 16,\n                size_frac_high = 17,\n                tara_id01 = 18,\n                tara_id02 = 19,\n                tara_id03 = 20) %&gt;%\n  mutate(date_time = lubridate::ymd_hms(date_time)) %&gt;% \n  dplyr::rename_with(.cols = 21:last_col(), ~ stringr::str_c('PANGAEA.875579_', str_pad(21:123, side = \"left\", pad = \"0\", width = 3)))\n\n# save the data for reuse\nreadr::write_rds(PANGAEA_875579, here::here(\"_data_raw\", \"PANGAEA_875579.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::file_delete(tmpdir)\n\n\nThis is information describing contents of the columns in this data set.\n\n\nShow/hide code\nreadr::read_rds(here::here(\"_data_raw\", \"PANGAEA_875579_desc.rds\"))",
    "crumbs": [
      "1) Download TARA environmental data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Retrieve, format, and impute environmental data associated with marine ’omics data sets",
    "section": "",
    "text": "This is a collection of code that should serve to make it easier to programmatically access, filter, and manipulate environmental data from various projects that sampled the ocean along with some kind of ’Omics data. At the moment this includes:\n\nTara Oceans expedition. The code downloads data directly from the PANGAEA Data Publisher (predominantly from here: https://doi.pangaea.de/10.1594/PANGAEA.875582) and saves slightly formatted versions locally for easy access.\nOther features will likely be incorporated here, stay tuned…\n\n\n\nWe follow the convention that only raw, unmodified, unfiltered, and non-subsetted datafiles obtained directly from database sources (including journal article metadata) are placed in the _data_raw directory. These should never be modified or changed. All data derived from these _data_raw files (including modification, filtering, and subsetting) are placed in the data directory\n\n\n\nVarious external databases are accessed and used here. This includes the MIT DARWIN model accessed from Simons Collaborative Marine Atlas Project, and environmental measurements (hydrography, biogeochemistry) from PANGAEA. You will need to register with Simons CMAP, obtain an API key, then download the cmap4r package in order to access data from the MIT DARWIN model. The rest of the databases don’t have API access restrictions and they are accessed programatically in the scripts.\nAll data and code in this GitHub repository (https://github.com/slhogle/omicsOceansEnvData) is provided under GNU AGPL3. The rendered project site is available at https://slhogle.github.io/omicsOceansEnvData/, which has been produced using Quarto notebooks. The content on the rendered site is released under the CC BY 4.0. This repository hosts all code and data for this project including the code necessary to fully recreate the rendered webpage.\nAn archived release of the code here is available from Zenodo:\n\n\n\nThe project uses renv to create reproducible environment to execute the code in this project. See here for a brief overview on collaboration and reproduction of the entire project. To get up and running you can do:\ninstall.packages(\"renv\")\nrenv::restore()\n\n\n\n\nDutkiewicz, S., A.E. Hickman, O. Jahn, W.W. Gregg, C.B. Mouw, and M.J. Follows. (2015) Capturing optically important constituents and properties in a marine biogeochemical and ecosystem model. Biogeoscience, 12, 4447-4481 doi:10.5194/bg-12-4447-2015\nForget, G., Campin, J.-M., Heimbach, P., Hill, C. N., Ponte, R. M., and Wunsch, C. (2015) ECCO version 4: an integrated framework for non-linear inverse modeling and global ocean state estimation, Geosci. Model Dev., 8, 3071-3104, doi:10.5194/gmd-8-3071-2015\nForget, G., D. Ferreira, and X. Liang. (2015) On the observability of turbulent transport rates by argo: supporting evidence from an inversion experiment. Ocean Science, 11, 839–853, doi:10.5194/os-11-839-2015\nForget, G. and R. Ponte. (2015) The partition of regional sea level variability. Progress in Oceanography, 137, 173–195, doi:10.1016/j.pocean.2015.06.002\nForget, G., 2018: Initial, preliminary version of the CBIOMES-global model setup and documentation (Version v0.0.1). Zenodo. http://doi.org/10.5281/zenodo.1343303\nForget, G. (2019) Update MITgcm & DarwinProject elements (Version v0.1.0). Zenodo. http://doi.org/10.5281/zenodo.2653669\nWard, B.A., S. Dutkiewicz, O. Jahn, and M.J. Follows. (2012) A size-structured food-web model for the global ocean. Limnol. Oceanogr., 57, 1877-1891. doi:10.4319/lo.2012.57.6.1877\nPesant, S. et al. (2015) Open science resources for the discovery and analysis of Tara Oceans data. Sci. Data 2:150023 doi: 10.1038/sdata.2015.23 https://aslopubs.onlinelibrary.wiley.com/doi/10.1002/lom3.10439\nGuidi, Lionel; Picheral, Marc; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about sensor data in the targeted environmental feature. PANGAEA, https://doi.org/10.1594/PANGAEA.875576\nAshkezari MD, Hagen NR, Denholtz M, Neang A, Burns TC, Morales RL, Lee CP, Hill CN, Armbrust EV. 2021. Simons Collaborative Marine Atlas Project (Simons CMAP): An open‐source portal to share, visualize, and analyze ocean data. Limnol Oceanogr Methods 19:488–496. doi: 10.1002/lom3.10439"
  },
  {
    "objectID": "index.html#availability",
    "href": "index.html#availability",
    "title": "Retrieve, format, and impute environmental data associated with marine ’omics data sets",
    "section": "",
    "text": "Various external databases are accessed and used here. This includes the MIT DARWIN model accessed from Simons Collaborative Marine Atlas Project, and environmental measurements (hydrography, biogeochemistry) from PANGAEA. You will need to register with Simons CMAP, obtain an API key, then download the cmap4r package in order to access data from the MIT DARWIN model. The rest of the databases don’t have API access restrictions and they are accessed programatically in the scripts.\nAll data and code in this GitHub repository (https://github.com/slhogle/omicsOceansEnvData) is provided under GNU AGPL3. The rendered project site is available at https://slhogle.github.io/omicsOceansEnvData/, which has been produced using Quarto notebooks. The content on the rendered site is released under the CC BY 4.0. This repository hosts all code and data for this project including the code necessary to fully recreate the rendered webpage.\nAn archived release of the code here is available from Zenodo:"
  },
  {
    "objectID": "index.html#reproducibility",
    "href": "index.html#reproducibility",
    "title": "Retrieve, format, and impute environmental data associated with marine ’omics data sets",
    "section": "",
    "text": "The project uses renv to create reproducible environment to execute the code in this project. See here for a brief overview on collaboration and reproduction of the entire project. To get up and running you can do:\ninstall.packages(\"renv\")\nrenv::restore()"
  },
  {
    "objectID": "index.html#relevant-references",
    "href": "index.html#relevant-references",
    "title": "Retrieve, format, and impute environmental data associated with marine ’omics data sets",
    "section": "",
    "text": "Dutkiewicz, S., A.E. Hickman, O. Jahn, W.W. Gregg, C.B. Mouw, and M.J. Follows. (2015) Capturing optically important constituents and properties in a marine biogeochemical and ecosystem model. Biogeoscience, 12, 4447-4481 doi:10.5194/bg-12-4447-2015\nForget, G., Campin, J.-M., Heimbach, P., Hill, C. N., Ponte, R. M., and Wunsch, C. (2015) ECCO version 4: an integrated framework for non-linear inverse modeling and global ocean state estimation, Geosci. Model Dev., 8, 3071-3104, doi:10.5194/gmd-8-3071-2015\nForget, G., D. Ferreira, and X. Liang. (2015) On the observability of turbulent transport rates by argo: supporting evidence from an inversion experiment. Ocean Science, 11, 839–853, doi:10.5194/os-11-839-2015\nForget, G. and R. Ponte. (2015) The partition of regional sea level variability. Progress in Oceanography, 137, 173–195, doi:10.1016/j.pocean.2015.06.002\nForget, G., 2018: Initial, preliminary version of the CBIOMES-global model setup and documentation (Version v0.0.1). Zenodo. http://doi.org/10.5281/zenodo.1343303\nForget, G. (2019) Update MITgcm & DarwinProject elements (Version v0.1.0). Zenodo. http://doi.org/10.5281/zenodo.2653669\nWard, B.A., S. Dutkiewicz, O. Jahn, and M.J. Follows. (2012) A size-structured food-web model for the global ocean. Limnol. Oceanogr., 57, 1877-1891. doi:10.4319/lo.2012.57.6.1877\nPesant, S. et al. (2015) Open science resources for the discovery and analysis of Tara Oceans data. Sci. Data 2:150023 doi: 10.1038/sdata.2015.23 https://aslopubs.onlinelibrary.wiley.com/doi/10.1002/lom3.10439\nGuidi, Lionel; Picheral, Marc; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about sensor data in the targeted environmental feature. PANGAEA, https://doi.org/10.1594/PANGAEA.875576\nAshkezari MD, Hagen NR, Denholtz M, Neang A, Burns TC, Morales RL, Lee CP, Hill CN, Armbrust EV. 2021. Simons Collaborative Marine Atlas Project (Simons CMAP): An open‐source portal to share, visualize, and analyze ocean data. Limnol Oceanogr Methods 19:488–496. doi: 10.1002/lom3.10439"
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "",
    "text": "This code loads required libraries and sets global variables\n\n\nShow/hide code\nlibrary(tidyverse)\nlibrary(here)\nlibrary(lubridate)\nlibrary(fuzzyjoin)",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html#combine-all-pangaea-datasets-with-biosamples",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html#combine-all-pangaea-datasets-with-biosamples",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "3.1 Combine all Pangaea datasets with BioSamples",
    "text": "3.1 Combine all Pangaea datasets with BioSamples\n\n\nShow/hide code\ntara_biosamples_joined01 &lt;- left_join(tara_biosamples, PANGAEA_875575, by = join_by(tara_barcode_num, tara_station)) %&gt;% \n  left_join(dplyr::select(PANGAEA_875576, tara_barcode_num, tara_station, date_time, 21:last_col()), \n            by = join_by(tara_barcode_num, tara_station)) %&gt;% \n  left_join(dplyr::select(PANGAEA_875577, tara_barcode_num, tara_station, 21:last_col()), by = join_by(tara_barcode_num, tara_station)) %&gt;% \n  left_join(dplyr::select(PANGAEA_875579, tara_barcode_num, tara_station, 21:last_col()), by = join_by(tara_barcode_num, tara_station)) %&gt;% \n  left_join(dplyr::select(PANGAEA_842237, tara_station, latitude, longitude), by = join_by(tara_station))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html#fill-missing-observations-with-adjacent-data",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html#fill-missing-observations-with-adjacent-data",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "3.2 Fill missing observations with adjacent data",
    "text": "3.2 Fill missing observations with adjacent data\nThere are 7 cases where there is not single recorded depth for an observation, but rather a depth range (depth_min to depth_max).\n\n\nShow/hide code\ntara_biosamples_joined01 %&gt;% \n  filter(is.na(depth)) %&gt;% \n  distinct(tara_barcode_num, tara_station, env_ontology, depth, depth_min, depth_max, date_time)\n\n\n\n  \n\n\n\nLater it will make our lives easier if there are actual values for these depths and not NAs. We fill these depths with the mean of the depth range.\nAlso in some cases nutrients or sensor data will not be joined even though there is a measurement at that particular station/depth. We will group by station and depth and then fill those observations from the same station/depth.\n\n\nShow/hide code\ntara_biosamples_joined02 &lt;- tara_biosamples_joined01 %&gt;% \n  mutate(depth = if_else(is.na(depth), (depth_max - depth_min)/2, depth)) %&gt;% \n  arrange(tara_station, depth) %&gt;% \n  group_by(tara_station, depth, depth_min, depth_max) %&gt;% \n  fill(20:last_col(), .direction = \"downup\") %&gt;% \n  ungroup()",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html#fill-missing-observations-with-whole-water-column-data-pangaea.875579",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html#fill-missing-observations-with-whole-water-column-data-pangaea.875579",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "3.3 Fill missing observations with “whole water column” data (PANGAEA.875579)",
    "text": "3.3 Fill missing observations with “whole water column” data (PANGAEA.875579)\nNow we will fill missing observations with direct observations taken from the “whole water column.”\n\nWe will take bottle samples as the starting point (PANGAEA_875575)\nIf a bottle observation is missing fill with the closes CTD sensor observation (PANGAEA_875576)\nIf CTD sensor observation is missing fill with “whole water column” data (PANGAEA.875579). TBH I actually don’t understand where this data comes from. The PI listed is Sabrina Speich who is different than the most common PIs (Pesant and Guidi). But from what I can tell this is not the output of a model but somehow a direct observation corresponding to a Tara station.\nFinally, if none of the three above exist we will fill the data with the output from the MIT Darwin model.\n\nThis function creates a new variable replacing a variable from either PANGAEA_875575 or PANGAEA_875576 with the corresponding SRF/MIX/DCM/MES measurement from PANGAEA.875579\n\n\nShow/hide code\nreplace_w_875579 &lt;- function(.data, varname, target, srf, mix, dcm){\n  .data %&gt;% \n    mutate(\"{varname}\" := if_else(!is.na({{ target }}), {{ target }},\n          if_else(str_detect(env_ontology, \"SRF\"), {{ srf }},\n                  if_else(str_detect(env_ontology, \"MIX\"), {{ mix }}, \n                          if_else(str_detect(env_ontology, \"DCM\"), {{ dcm }}, NA_real_)))))\n}\n\nsimple_replace &lt;- function(.data, varname, target, replace){\n  .data %&gt;% \n    mutate(\"{varname}\" := if_else(is.na({{ target }}), {{ replace }}, {{ target }}))\n}\n\n\nCall the above function for each of the 10 variables of interest\n\n\nShow/hide code\ntara_biosamples_joined02_replaced &lt;- tara_biosamples_joined02 %&gt;%\n  replace_w_875579(\"density\",     PANGAEA.875576_047, PANGAEA.875579_074, PANGAEA.875579_077, PANGAEA.875579_079) %&gt;% \n  replace_w_875579(\"temperature\", PANGAEA.875576_027, PANGAEA.875579_064, PANGAEA.875579_067, PANGAEA.875579_069) %&gt;% \n  replace_w_875579(\"salinity\",    PANGAEA.875576_037, PANGAEA.875579_054, PANGAEA.875579_057, PANGAEA.875579_059) %&gt;% \n  replace_w_875579(\"chl_a\",       PANGAEA.875576_077, PANGAEA.875579_094, PANGAEA.875579_097, PANGAEA.875579_099) %&gt;% \n  replace_w_875579(\"dO2\",         PANGAEA.875576_057, PANGAEA.875579_104, PANGAEA.875579_107, PANGAEA.875579_109) %&gt;% \n  replace_w_875579(\"DIN\",         PANGAEA.875575_031, PANGAEA.875579_114, PANGAEA.875579_117, PANGAEA.875579_119) %&gt;% \n    simple_replace(\"DIN\",         DIN, PANGAEA.875577_045) %&gt;% \n    simple_replace(\"NO2\",         PANGAEA.875575_021, PANGAEA.875577_043) %&gt;% \n  mutate(FeT = PANGAEA.875577_039, \n         PO4 = PANGAEA.875575_026,\n         SiO2 = PANGAEA.875575_036) %&gt;% \n  relocate(tara_barcode_num, tara_station, env_ontology, latitude, longitude, date_time, depth, depth_min, depth_max, \n           density, temperature, salinity, chl_a, dO2, DIN, NO2, FeT, PO4, SiO2)\n\n\nFix some stuff with dates\n\n\nShow/hide code\nstatistical_mode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\ntara_biosamples_joined02_replaced &lt;- tara_biosamples_joined02_replaced %&gt;% \n  # convert the date_time to only date. This ensures that when you are grouping\n  # by tara_station and date_time that you don't expand the results to include\n  # multiple times within a single station\n  mutate(date_time = lubridate::as_date(stringr::str_extract(date_time, \"^\\\\d{4}-\\\\d{2}-\\\\d{2}\"))) %&gt;% \n  group_by(tara_station) %&gt;% \n  # in the case that there are multiple days sampled at a station take the most\n  # common day to represent the whole station\n  mutate(date_time = statistical_mode(date_time)) %&gt;% \n  ungroup()\n\n\nNow after we have filled observations with data internally available from the Tara Pangaea collection, we need to find which stations still have missing data observations for one or more these variables.\n\n\nShow/hide code\ntarget_vars &lt;- c(\"density\", \"temperature\", \"salinity\", \"chl_a\", \"dO2\", \"DIN\", \"NO2\", \"FeT\", \"PO4\", \"SiO2\")\n\nmissing &lt;- tara_biosamples_joined02_replaced %&gt;% \n  filter(if_any(all_of(target_vars), is.na)) %&gt;%\n  summarise(across(all_of(target_vars), ~any(is.na(.))),\n            .by = c(tara_station, env_ontology, depth, depth_min, depth_max, latitude, longitude, date_time))\n\n\nMost missing observations are because of PO4 and SiO2\n\n\nShow/hide code\nmissing %&gt;% \n  summarize(across(all_of(target_vars), sum))\n\n\n\n  \n\n\n\nAnd this is for 56 different tara stations\n\n\nShow/hide code\ndistinct(missing, tara_station) %&gt;% \n  count()\n\n\n\n  \n\n\n\nThis level of completion is pretty OK I think… To replace the missing fields I will use modeled variables from the MIT Darwin model. These can be obtained from Simons CMAP.\nSet the api-key for CMAP. This allows your R session to communicate with their backend database. You will need to get your own key following instructions here.\n\n\nShow/hide code\nlibrary(cmap4r)\ncmap4r::set_authorization(reset = TRUE)\ncmap4r::set_authorization(cmap_key = \"KEY-GOES-HERE\")\n\n\nDownload a local copy of the CMAP catalog. Useful for querying later…\n\n\nShow/hide code\nlocal_cat &lt;- cmap4r::get_catalog() %&gt;%\n  select(Variable, Table_Name, Unit, Sensor, Unit)\n\nwrite_tsv(local_cat, here::here(\"_data_raw\", \"cmap\", \"cmap_catalog.tsv\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html#fill-missing-observations-with-darwin-model-nutrients-output",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html#fill-missing-observations-with-darwin-model-nutrients-output",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "3.4 Fill missing observations with Darwin model Nutrients output",
    "text": "3.4 Fill missing observations with Darwin model Nutrients output\n\n3.4.1 Darwin coordinates for nutrients\nCMAP has some select nutrient concentrations available from the 3-day averagedDarwin Model output. These include\n\n\nShow/hide code\nlocal_cat %&gt;% \n  filter(Table_Name == \"tblDarwin_Nutrient\")\n\n\n\n  \n\n\n\nNot exactly clear what the units are for these nutrients, but my guess is mmol m-3 since most other concentration units are per 1 m3 unit volume.\nNow we will get only the stations with missing nutrients in tblDarwin_Nutrient\n\n\nShow/hide code\nmissing_nuts &lt;- missing %&gt;% \n  tidyr::pivot_longer(c(-tara_station, -env_ontology, -depth, -depth_min, -depth_max, -latitude, -longitude, -date_time)) %&gt;% \n  dplyr::filter(value == TRUE) %&gt;% \n  dplyr::select(tara_station, env_ontology, latitude, longitude, date_time, depth, depth_min, depth_max) %&gt;% \n  dplyr::distinct()\n\n\nNow retrieve parameters from these stations that can be used to query CMAP database. We need a start latitude, ending latitude, starting longitude, ending longitude, starting depth, ending depth, and starting date and ending date. Note: here we don’t bother with depths because when you query all the variables in the CMAP database it returns all depths regardless of what you provide to the function (bug? feature?)\n\n\nShow/hide code\ncoord_range &lt;- function(x, f, offset, negate = FALSE){\n  return(if_else(negate, -(f(max(abs(x))) + offset), f(max(abs(x))) + offset))\n}\n\nmissing_nuts_nested &lt;- missing_nuts %&gt;% \n  group_by(tara_station) %&gt;% \n  mutate(lat1 = if_else(latitude &lt; 0,   coord_range(latitude, ceiling, 1, TRUE),  coord_range(latitude, floor, -1, FALSE)),\n         lat2 = if_else(latitude &lt; 0,   coord_range(latitude, floor, -1, TRUE),   coord_range(latitude, ceiling, 1, FALSE)),\n         lon1 = if_else(longitude &lt; 0,  coord_range(longitude, ceiling, 1, TRUE),  coord_range(longitude, floor, -1, FALSE)),\n         lon2 = if_else(longitude &lt; 0,  coord_range(longitude, floor, -1, TRUE), coord_range(longitude, ceiling, 1, FALSE))) %&gt;%\n  dplyr::mutate(dt1 = floor_date(date_time, 'month'),\n                dt2 = ceiling_date(date_time, 'month')) %&gt;% \n  ungroup() %&gt;% \n  nest(original_data = c(env_ontology:depth_max)) %&gt;% \n  nest(dw_query = c(lat1:dt2))\n\n\nNow make the call querying the CMAP remote database. This maps a separate call to every unique missing Tara Station. Even though this isn’t very efficient it is faster and takes less space that just downloaded the Darwin output for the entire ocean and then later filtering to the coordinates of interest.\n\n\nShow/hide code\nmissing_nuts_nested_darwin &lt;- missing_nuts_nested %&gt;% \n  mutate(\n    tbl = map(\n      dw_query,\n      function(df) cmap4r::get_spacetime(\n        tableName = 'tblDarwin_Nutrient',\n        varName = '*',\n        dt1 = as.character(df$dt1),\n        dt2 = as.character(df$dt2),\n        lat1 = df$lat1,\n        lat2 = df$lat2,\n        lon1 = df$lon1,\n        lon2 = df$lon2)))\n\n# save this for later to speed up quarto renders\nwrite_rds(missing_nuts_nested_darwin, here::here(\"_data_raw\", \"tara\", \"cmap_missing_nuts.rds\"))\n\n\n\n\n3.4.2 Filter Darwin output to Tara coordinates\nNow we need to whittle down the Darwin model output to only the time, depth, and coordinates of interest. We do this by\n\nFuzzy joining on latitude and longitude using fuzzyjoin::geo_inner_join. Briefly this calculates the Haversine distance between two sets of coordinates and keeps only those with distance magnitude less than max_dist (here we set this to 65 kilometers). This allows us to keep only coordinates that are as close as possible to the sampled Tara coordinates. Later we select for the smallest Haversine distance to select a point from the model grid that is closest to the Tara station. Sometimes these coordinates will be a land cell on the Darwin grid and will return NAs so we use drop_na to only include coordinates in the ocean with nutrients.\nNext we calculate the duration of time between the Tara observation and the time step from the Darwin Model. Note this is the 3-day averaged model output. We then filter to only include model output that is closest in time (shortest duration) to the Tara observation.\nFinally, we need to make a measure of the distance between the sampled Tara depth and the model output depth. In the upper 250 the depth is high resolution so usually we find a depth between depth_min and depth_max in the model output. Deeper in the ocean the model output is only every 100 meters or more so we need to filter on the smallest possible difference from the Tara depth\n\n\n\nShow/hide code\nmissing_nuts_nested_darwin_filtered &lt;- missing_nuts_nested_darwin %&gt;% \n  # unnest on the Darwin output. expand rows per Tara Station\n  unnest(tbl) %&gt;%\n  # select only relevant columns to make management easier\n  dplyr::select(tara_station, \n                date_time = time, latitude = lat, longitude = lon, depth,\n                PO4_dw = PO4, SiO2_dw = SiO2, O2_dw = O2) %&gt;%\n  # fuzzy join the Darwin output to the coordinates of missing data using the \n  # haversine distance and excluding joins that exceed 65 km in distance apart\n  fuzzyjoin::geo_inner_join(missing_nuts,\n                            by = c(\"latitude\", \"longitude\"),\n                            distance_col = \"geojoin_dist_km\",\n                            max_dist = 65) %&gt;% \n  # narrow down the data so we only consider matching Tara stations from the two datasets\n  filter(tara_station.x == tara_station.y) %&gt;%\n  # exclude any Darwin observations that have NAs for PO4, SiO2, or O2 (these are genarally land grids or seafloor)\n  filter(!(is.na(PO4_dw) & is.na(SiO2_dw) & is.na(O2_dw))) %&gt;% \n  # Group by unique variables for each Tara observation\n  group_by(tara_station.y, env_ontology, depth.y, depth_min, depth_max) %&gt;% \n  # Filter to include only matches with smallest distance between Darwin grid and the coords of the direct observation\n  filter(geojoin_dist_km == min(geojoin_dist_km)) %&gt;% \n  # do some type conversions for dates to allow subsequent calculations\n  mutate(date_time.x = lubridate::as_date(date_time.x),\n         date_time.y = lubridate::as_date(stringr::str_extract(date_time.y, \"^\\\\d{4}-\\\\d{2}-\\\\d{2}\"))) %&gt;% \n  # calculate the difference between the model output (3-day interval) and the sampling time of the direct observation\n  mutate(time_diff = as.duration(abs(interval(date_time.x, date_time.y)))) %&gt;% \n  # filter to only include matches with the smallest time difference\n  filter(time_diff == min(time_diff)) %&gt;% \n  # filter to only include matches with the smallest depth difference\n  filter(abs(depth.y - depth.x) == min(abs(depth.y - depth.x))) %&gt;% \n  ungroup() %&gt;% \n  dplyr::select(tara_station = tara_station.y, \n                depth = depth.y, depth_min, depth_max, env_ontology,\n                latitude = latitude.y, longitude = longitude.y, PO4_dw, SiO2_dw, O2_dw) %&gt;%\n  # take mean of multi-observations (e.g. if the real depth is 4, the closest\n  # depths from Darwin are 35 and 45 so we average the concentration from the\n  # two flanking depths)\n  summarize(across(PO4_dw:O2_dw, mean), \n            .by = c(tara_station:longitude))\n\n\n\n\n3.4.3 Join observed and Darwin Model output into single dataframe\n\n\nShow/hide code\ntara_biosamples_joined02_replaced02 &lt;- left_join(tara_biosamples_joined02_replaced, missing_nuts_nested_darwin_filtered, \n          by = join_by(tara_station, env_ontology, latitude, longitude, depth, depth_min, depth_max)) %&gt;% \n  simple_replace(\"SiO2\", SiO2, SiO2_dw) %&gt;%\n  simple_replace(\"dO2\",  dO2, O2_dw) %&gt;%\n  simple_replace(\"PO4\",  PO4, PO4_dw)",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html#impute-remaining-missing-observations",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html#impute-remaining-missing-observations",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "3.5 Impute remaining missing observations",
    "text": "3.5 Impute remaining missing observations\n\n\nShow/hide code\nlibrary(missRanger)\n\n\nThere are three Tara stations with missing observations. TARA_011 is missing chl_a, density, salinity and temperature, while the others are missing only chl_a\n\n\nShow/hide code\nmissing %&gt;% \n  dplyr::select(tara_station:chl_a) %&gt;%\n  tidyr::pivot_longer(c(-tara_station, -env_ontology, -depth, -depth_min, -depth_max, -latitude, -longitude, -date_time)) %&gt;% \n  dplyr::filter(value == TRUE) %&gt;% \n  group_by(tara_station, name) %&gt;% \n  count(value) %&gt;% \n  arrange(name)\n\n\n\n  \n\n\n\nSince this is only a few missing observations, we are going to impute them using the missRanger package, which uses the missForest random forest imputation approach.\nFirst only subset variables of interest and make the data unique\n\n\nShow/hide code\ntara_biosamples_joined02_replaced02_uniq &lt;- tara_biosamples_joined02_replaced02 %&gt;% \n  dplyr::select(tara_station:SiO2) %&gt;% \n  distinct()\n\n\nRun the missRanger algorithm to impute missing values. We impute density, temperature, salinity, chl_a by depth, density, temperature, salinity, chl_a, dO2, DIN, NO2, FeT, PO4, SiO2\n\n\nShow/hide code\n# set seed for reproducibility\nset.seed(35782)\ntara_biosamples_joined02_replaced02_uniq_rangerd &lt;- missRanger::missRanger(tara_biosamples_joined02_replaced02_uniq, \n                                                                           . ~ . - tara_station - env_ontology - latitude - longitude - date_time - depth_min - depth_max, pmm.k = 10, num.trees = 500)",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/03_harmonize_ncbi_pangaea.html#joining-and-replacing-missing-values-with-those-imputed",
    "href": "R/tara/03_harmonize_ncbi_pangaea.html#joining-and-replacing-missing-values-with-those-imputed",
    "title": "Harmonize environmental data and sequencing identifiers",
    "section": "3.6 Joining and replacing missing values with those imputed",
    "text": "3.6 Joining and replacing missing values with those imputed\nFirst get only the samples that needed salinity, temp, density, chl_a replaced from the imputed dataset\n\n\nShow/hide code\ntara_biosamples_joined02_replaced02_uniq_imputed &lt;- tara_biosamples_joined02_replaced02_uniq %&gt;% filter(if_any(everything(), is.na)) %&gt;% select(tara_station:depth_max)\n\ntara_biosamples_envdata_01 &lt;- inner_join(tara_biosamples_joined02_replaced02_uniq_rangerd, tara_biosamples_joined02_replaced02_uniq_imputed,\n           by = join_by(tara_station, env_ontology, latitude, longitude, date_time, depth, depth_min, depth_max))\n\n\nNext join those imputed samples to the full tara_biosamples_joined02_replaced02 table\n\n\nShow/hide code\ntara_biosamples_envdata_02 &lt;- right_join(tara_biosamples_envdata_01, tara_biosamples_joined02_replaced02,\n              by = join_by(tara_station, env_ontology, latitude, longitude, date_time, depth, depth_min, depth_max))\n\n\n\n3.6.1 Detour to add some additional geographic info\nNext we want to add some geographic information to the dataset like longhurst code, ocean identifier, and the distance to the coast. We will calculate the distance to the nearest coast using ggOceanMaps::dist2land. Inspired by this blogpost\n\n\nShow/hide code\nlibrary(ggOceanMaps)\nlibrary(rnaturalearth)\nlibrary(sf)\n\n\nLoad coastline data at the largest most coarse scale (110) and also subset PANGAEA_842237 to only coordinates and station identifier\n\n\nShow/hide code\ncoast &lt;- rnaturalearth::ne_coastline(scale=110, returnclass = \"sf\")\ndata &lt;- dplyr::select(PANGAEA_842237, tara_station, latitude, longitude, )\n\n\nPlot to check\n\n\nShow/hide code\nplot(coast['featurecla'])\n\n\n\n\n\n\n\n\n\nThis function calculates great circle spherical distances (in kilometers) from a coordinate in the ocean to the nearest coastline using the st_distance function.\n\n\nShow/hide code\ndist2land_df &lt;- ggOceanMaps::dist2land(data, shapefile = coast) %&gt;% \n  dplyr::select(tara_station, dist_to_coastline = ldist)\n\n\nUsed longitude and latitude as input coordinate column names in data\n\n\nUsing custom land shapes.\n\n\nCalculating distances...\n\n\nReturning great circle spherical distances from land as kilometers.\n\n\nJoin the distance to coastline to other general large scale features like longhurst provinces\n\n\nShow/hide code\nocean_feats_df &lt;- PANGAEA_842237 %&gt;%\n  dplyr::select(tara_station, ocean_id = PANGAEA.842237_016, longhurst_biome = PANGAEA.842237_015, \n                longhurst_code = PANGAEA.842237_018, bathy_depth = PANGAEA.842237_012) %&gt;% \n  left_join(dist2land_df, by = join_by(tara_station))\n\n\n\n\n3.6.2 Finalize\nNow do the final joining to the full imputed data set, replace missing values with the imputed values, and select key variables\n\n\nShow/hide code\ntara_biosamples_envdata_final &lt;- left_join(tara_biosamples_envdata_02, ocean_feats_df, by = join_by(tara_station)) %&gt;% \n  simple_replace(\"density\", density.y, density.x) %&gt;% \n  simple_replace(\"salinity\", salinity.y, salinity.x) %&gt;%\n  simple_replace(\"temperature\", temperature.y, temperature.x) %&gt;%\n  simple_replace(\"chl_a\", chl_a.y, chl_a.x) %&gt;% \n  select(tara_barcode_num, sra_acc_num:ena_acc_num, tara_station:date_time, size_low_thresh, size_high_thresh,\n         ocean_id, longhurst_code, longhurst_biome, bathy_depth, dist_to_coastline,\n         depth:depth_max, temperature, salinity, density, chl_a,\n         dO2 = dO2.y, DIN = DIN.y, NO2 = NO2.y, FeT = FeT.y, PO4 = PO4.y, SiO2 = SiO2.y)\n\n\nFinal check to see if there is missing entries in this dataframe - good to go\n\n\nShow/hide code\ntara_biosamples_envdata_final %&gt;% \n  filter(if_any(everything(), is.na))\n\n\n\n  \n\n\n\nSave for later\n\n\nShow/hide code\nwrite_tsv(tara_biosamples_envdata_final, here::here(\"data\", \"tara\", \"tara_biosamples_envdata_final.tsv\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Harmonize env and 'omics data"
    ]
  },
  {
    "objectID": "R/tara/01_download_data_ncbi.html",
    "href": "R/tara/01_download_data_ncbi.html",
    "title": "Map NCBI sequencing and Tara identifiers",
    "section": "",
    "text": "This code loads required libraries and sets global variables\n\n\nShow/hide code\nlibrary(tidyverse)\nlibrary(here)\nlibrary(fs)\nlibrary(readxl)\nlibrary(sf)\nlibrary(mapview)\nlibrary(rentrez)\nlibrary(xml2)",
    "crumbs": [
      "1. Tara oceans workflow",
      "1) BioSamples at NCBI"
    ]
  },
  {
    "objectID": "R/tara/01_download_data_ncbi.html#functions",
    "href": "R/tara/01_download_data_ncbi.html#functions",
    "title": "Map NCBI sequencing and Tara identifiers",
    "section": "3.1 Functions",
    "text": "3.1 Functions\n\n\nShow/hide code\nget_biosamples_from_bioproject &lt;- function(bioproject_id) {\n  entrez_hit &lt;- rentrez::entrez_link(dbfrom = \"bioproject\", id = bioproject_id, db = \"biosample\")\n  entrez_hit$links$bioproject_biosample_all\n}\n\nget_biosamples_xml &lt;- function(biosample_ids){\n  # sleep for 3 seconds. This is necessary so to not send to many entrez\n  # requests in a time interval entrez will not allow more than 3 requests per\n  # second. Using 3 seconds is the smallest time I tested that didn't allow too\n  # many entrez requests to overlap\n  Sys.sleep(3)\n  rentrez::entrez_fetch(db=\"biosample\", id = biosample_ids, rettype = \"xml\") %&gt;% \n    xml2::read_xml()\n}\n\nget_xml_field &lt;- function(input_xml, attr_reg_exp) {\n  input_xml %&gt;% \n    xml2::xml_find_all(xpath = attr_reg_exp) %&gt;%\n    xml2::xml_text()\n}\n\nget_attribute_name_dumb_regex &lt;- function(biosample_xml, search_string){\n  # stupid edge cases for when attribute names are different for different\n  # biosamples in the same bioproject!\n  low_upp_find &lt;- c(get_xml_field(biosample_xml, paste0(\"//*[@attribute_name='\", search_string, \"']\")),\n                    get_xml_field(biosample_xml, paste0(\"//*[@attribute_name='\", str_to_title(search_string), \"']\")))\n  ifelse(rlang::is_empty(low_upp_find), NA_character_, low_upp_find)\n}\n\nbiosampid_to_biosamp_tibble &lt;- function(biosample_ids){\n  biosample_xml &lt;- get_biosamples_xml(biosample_ids)\n  # prepare for dividing xml document into tibble structure where each row\n  # is a different bioproject\n  rows &lt;- xml2::xml_find_all(biosample_xml, xpath = \"//BioSample\") \n  # this is stupid but I can't figure out a better way to do this. Tibbles can\n  # not accept exotic column types like nodeset To put the xml nodeset into a\n  # tibble it must be converted into a list first, because tibbles can accept\n  # lists. Then I reconvert it back to an xml document using `as_xml_document`\n  # but this must be inside a larger list structure that assigns a name to the\n  # content hence the call to `list(BioSample = .)`\n  rows_df &lt;- tibble::tibble(row = seq_along(rows),\n                  nodeset = xml2::as_list(rows),\n                  biosample_id = biosample_ids) %&gt;% \n  mutate(nodeset = purrr::map(nodeset,~ xml2::as_xml_document(list(BioSample = .))))\n  \n  # now do the final xml extraction and field placement into a tibble\n  dplyr::mutate(rows_df, \n      biosample_acc_num = purrr::map(nodeset, ~ get_xml_field(., \"./Ids/Id[@db='BioSample']\")),\n      sra_acc_num       = purrr::map(nodeset, ~ get_xml_field(., \"./Ids/Id[@db='SRA']\")),\n      external_id       = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"external id\")),\n      tara_station      = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"sampling station\")),\n      sample_name       = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"sample name\")),\n      tara_event        = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"event label\")),\n      campaign          = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"sampling campaign\")),\n      marine_region     = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"marine region\")),\n      latitude          = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"latitude start\")),\n      longitude         = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"longitude start\")),\n      depth             = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"depth\")),\n      env_feature       = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"environment (feature)\")),\n      size_low_thresh   = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"size fraction lower threshold\")),\n      size_high_thresh  = purrr::map(nodeset, ~ get_attribute_name_dumb_regex(., \"size fraction upper threshold\"))\n      ) %&gt;% \n    dplyr::select(-nodeset) %&gt;% \n    tidyr::unnest(cols = everything())\n}\n\nbioproj_to_biosamp_tibble &lt;- function(bioproject_id){\n  biosample_ids &lt;- get_biosamples_from_bioproject(bioproject_id)\n  # split into chunks of 100 entries per chunk. This is to prevent too many\n  # overlapping entrez requests\n  biosample_ids_chunked &lt;- split(biosample_ids, ceiling(seq_along(biosample_ids)/100))\n  purrr::map(biosample_ids_chunked, biosampid_to_biosamp_tibble) %&gt;% \n    purrr::list_rbind()\n}",
    "crumbs": [
      "1. Tara oceans workflow",
      "1) BioSamples at NCBI"
    ]
  },
  {
    "objectID": "R/tara/01_download_data_ncbi.html#get-biosamples-and-tara-stations-from-ncbi",
    "href": "R/tara/01_download_data_ncbi.html#get-biosamples-and-tara-stations-from-ncbi",
    "title": "Map NCBI sequencing and Tara identifiers",
    "section": "3.2 Get BioSamples and Tara stations from NCBI",
    "text": "3.2 Get BioSamples and Tara stations from NCBI\nBioSamples are kind of the master record linking sequencing data at ENA, NCBI, and Pangaea.de, thus it’s important we get this information.\nLoop over all different bioprojects and read into a single tibble. NCBI Entrez servers can be kind of pissy sometimes and will reject your requests. I don’t know why this happens, but usually just keep trying until it works. Once it works save the output so that we don’t need to do this again…\n\n\nShow/hide code\nall_tara_samps &lt;- purrr::map(c(196960, 196958, 213098, 214077, 287904, 288558, 288560), \n                             bioproj_to_biosamp_tibble) %&gt;% \n  purrr::list_rbind()\n\nreadr::write_rds(all_tara_samps, here::here(\"_data_raw\", \"tara\", \"all_tara_samps.rds\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "1) BioSamples at NCBI"
    ]
  },
  {
    "objectID": "R/tara/01_download_data_ncbi.html#inspect-downloaded-data",
    "href": "R/tara/01_download_data_ncbi.html#inspect-downloaded-data",
    "title": "Map NCBI sequencing and Tara identifiers",
    "section": "3.3 Inspect downloaded data",
    "text": "3.3 Inspect downloaded data\nSanity check. The External Id present in the xml Attributes should be equivalent to the BioSample accession present in the xml Ids.\n\n\nShow/hide code\n# This checks out...\nall_tara_samps %&gt;% \n  # some external ids are NA\n  dplyr::filter(!is.na(external_id)) %&gt;% \n  dplyr::filter(biosample_acc_num != external_id)\n\n\n\n  \n\n\n\nGood - there are no cases where External Id and BioSample do not match.",
    "crumbs": [
      "1. Tara oceans workflow",
      "1) BioSamples at NCBI"
    ]
  },
  {
    "objectID": "R/tara/01_download_data_ncbi.html#fill-missing-tara-stations",
    "href": "R/tara/01_download_data_ncbi.html#fill-missing-tara-stations",
    "title": "Map NCBI sequencing and Tara identifiers",
    "section": "3.4 Fill missing Tara Stations",
    "text": "3.4 Fill missing Tara Stations\nThere should be a Tara station ID for all these because that is critical for connecting to Pangaea environmental data. Find those without Tara Station\n\n\nShow/hide code\nall_tara_samps %&gt;% \n  dplyr::filter(is.na(tara_station))\n\n\n\n  \n\n\n\nWhat the hell BioSample SAMEA6823711 appears to actually be some human ear metagenome!? So that sample should be excluded. The other missing stations only have the sample_name populated. Indeed at NCBI and ENA these samples don’t have any distinguishing metadata other than this sample_name key. After doing some googling I found this paper and Supplementary Table 1 in the supplementary material contains these sample names that can allow us to hopefully match up these samples to Tara stations.\n\n\nShow/hide code\n# create temporary location to decompress\ntmpfile &lt;- fs::file_temp()\n\ndownload.file(\"https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-023-05962-4/MediaObjects/41586_2023_5962_MOESM3_ESM.xlsx\", \n              tmpfile, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\nsupp01 &lt;- readxl::read_excel(tmpfile, sheet = 1, skip=2) %&gt;% \n  dplyr::rename_with(~stringr::str_to_lower(.), dplyr::everything())\n\nsupp02 &lt;- readxl::read_excel(tmpfile, sheet = 2, skip=2) %&gt;% \n  dplyr::rename_with(~stringr::str_to_lower(.), dplyr::everything()) %&gt;% \n  dplyr::rename(sample_name = metagenome_id, size_category = size_categorie)\n\n# Remove temp location\nfs::file_delete(tmpfile)\n\n\n\n\nShow/hide code\nall_tara_samps %&gt;% \n  dplyr::filter(is.na(tara_station)) %&gt;% \n  dplyr::select(biosample_acc_num, sample_name) %&gt;% \n  tidyr::separate(sample_name, into = c(\"a\", \"b\", \"c\", \"sample_name\", \"e\"), sep = \"_\") %&gt;% \n  dplyr::filter(!is.na(sample_name)) %&gt;% \n  dplyr::distinct(sample_name) %&gt;% \n  dplyr::left_join(supp02)\n\n\nWarning: Expected 5 pieces. Missing pieces filled with `NA` in 31 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\nJoining with `by = join_by(sample_name)`\n\n\n\n  \n\n\n\nDamn, so even some of these sample IDs are missing from the supplementary of that paper.\nActually, now I see that these sample_names are codes with meanings. The first number is the Tara Station, next is depth range (either SURface or DCM), next number I assume is some kind of replicate, then there is a size fraction code, and then everything ends with 11 for some reason.\nWe can parse this information to fill in the missing sample information\n\n\nShow/hide code\nmissing_samps &lt;- all_tara_samps %&gt;% \n  dplyr::filter(is.na(tara_station)) %&gt;% \n  dplyr::select(row, biosample_id, biosample_acc_num, sra_acc_num, external_id, sample_name) %&gt;% \n  tidyr::separate(sample_name, into = c(\"a\", \"b\", \"c\", \"sample_name\", \"e\"), sep = \"_\") %&gt;% \n  dplyr::filter(!is.na(sample_name)) %&gt;% \n  dplyr::mutate(tara_station = stringr::str_extract(sample_name, \"^(\\\\d+)(SUR|DCM)(\\\\d)([A-Z]+)\\\\d\\\\d\", group = 1),\n                  depthrange = stringr::str_extract(sample_name, \"^(\\\\d+)(SUR|DCM)(\\\\d)([A-Z]+)\\\\d\\\\d\", group = 2),\n                   replicate = stringr::str_extract(sample_name, \"^(\\\\d+)(SUR|DCM)(\\\\d)([A-Z]+)\\\\d\\\\d\", group = 3),\n                 filter_code = stringr::str_extract(sample_name, \"^(\\\\d+)(SUR|DCM)(\\\\d)([A-Z]+)\\\\d\\\\d\", group = 4)) %&gt;% \n  dplyr::mutate(tara_station = paste0(\"TARA_\", stringr::str_pad(tara_station, 3, side = \"left\", pad = 0))) %&gt;% \n  dplyr::left_join(\n    # this is just the information mapping filter code to actual size fractions\n    tibble::tibble(filter_code = c(\"QQSS\", \"GGMM\", \"MMQQ\", \"SSUU\"),\n       size_low_thresh = c(\"20\",   \"0.8\", \"5\",  \"180\"),\n       size_high_thresh = c(\"180\", \"5\",   \"20\", \"2000\"))\n    ) %&gt;% \n  dplyr::select(-a, -b, -c, -e, -filter_code) %&gt;% \n  dplyr::mutate(env_feature = dplyr::case_when(depthrange == \"DCM\" ~ \"deep chlorophyll maximum layer (ENVO:xxxxxxxx)\",\n                                               depthrange == \"SUR\" ~ \"surface water (ENVO:00002042) layer \"))\n\n\nWarning: Expected 5 pieces. Missing pieces filled with `NA` in 31 rows [1, 2, 3, 4, 5,\n6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\nJoining with `by = join_by(filter_code)`\n\n\nShow/hide code\nmissing_stations &lt;- dplyr::pull(dplyr::distinct(missing_samps, tara_station))\n\n\nNow add the missing samples back to the Tara samples with Tara station IDs\n\n\nShow/hide code\nall_tara_samps_fmt &lt;- all_tara_samps %&gt;% \n  dplyr::filter(!is.na(tara_station)) %&gt;% \n  dplyr::bind_rows(missing_samps) %&gt;% \n  dplyr::arrange(tara_station, env_feature, size_low_thresh, size_high_thresh) %&gt;% \n  dplyr::mutate(depth_class = dplyr::case_when(\n    stringr::str_detect(env_feature, \"surface water\") ~ \"SRF\",\n    stringr::str_detect(env_feature, \"deep chlorophyll maximum\") ~ \"DCM\",\n    stringr::str_detect(env_feature, \"mesopelagic\") ~ \"MES\",\n    stringr::str_detect(env_feature, \"epipelagic\") ~ \"MIX\",\n    TRUE ~ \"NONE\")\n    ) %&gt;% \n  dplyr::group_by(tara_station) %&gt;%\n  tidyr::fill(marine_region, campaign) %&gt;% \n  dplyr::group_by(tara_station, depth_class) %&gt;%\n  tidyr::fill(depth, latitude, longitude) %&gt;% \n  dplyr::ungroup() %&gt;% \n  dplyr::select(-depthrange, -replicate)\n\n\nNow join that information to the bioproject ID’s that I was provided by my collaborator\n\n\nShow/hide code\nall_tara_samps_fmt_joined &lt;- readr::read_tsv(here::here(\"_data_raw\", \"tara\", \"bioproject_ids_rogier.tsv\")) %&gt;% \n  dplyr::rename(biosample_acc_num = sample_accession) %&gt;% \n  dplyr::left_join(all_tara_samps_fmt) %&gt;%\n  dplyr::arrange(tara_station) %&gt;% \n  dplyr::select(-row, -external_id)\n\n\nRows: 1799 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (9): run_accession, sample_accession, experiment_accession, study_access...\ndbl (1): tax_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nJoining with `by = join_by(biosample_acc_num)`\n\n\nShow/hide code\nreadr::write_rds(all_tara_samps_fmt_joined, here::here(\"_data_raw\", \"tara\", \"tara_biosamples_mapped.rds\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "1) BioSamples at NCBI"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html",
    "href": "R/tara/02_download_data_pangaea.html",
    "title": "Download environmental data from Pangaea.de",
    "section": "",
    "text": "Citation:\nNote that the data sets zip bundled at https://doi.pangaea.de/10.1594/PANGAEA.875582 (above reference) are data sets Section 3.6, Section 3.7, Section 3.8 in the sections below.",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.842237",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.842237",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.1 Registry of Tara Stations from (PANGAEA.842237)",
    "text": "3.1 Registry of Tara Stations from (PANGAEA.842237)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.842237\nCitation:\n\nTara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2015): Registry of all stations from the Tara Oceans Expedition (2009-2013) [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.842237\n\n\n\nShow/hide code\nPANGAEA_842237 &lt;- pangaear::pg_data(doi = '10.1594/PANGAEA.842237')[[1]][['data']] %&gt;% \n  janitor::clean_names() %&gt;% \n  dplyr::rename_with(.cols = 1:last_col(), ~ stringr::str_c('PANGAEA.842237_', \n                                                            stringr::str_pad(1:49, side = \"left\", pad = \"0\", width = 3))) %&gt;% \n    dplyr::rename(tara_campaign = 1,\n                tara_station = 2,\n                date_time = 3,\n                date_time2 = 4,\n                latitude = 5,\n                longitude = 6,\n                lat_north = 7,\n                lat_south = 8,\n                long_east = 9,\n                long_west = 10,\n                time_day = 11)\n\n# save for later\nreadr::write_rds(PANGAEA_842237, here::here(\"_data_raw\", \"tara\", \"PANGAEA_842237.rds\"), compress = \"xz\", compression = 9L)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875581",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875581",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.2 Sequencing library information (PANGAEA.875581)",
    "text": "3.2 Sequencing library information (PANGAEA.875581)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875581\nCitation:\n\nAlberti, Adriana; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Methodology used in the lab for molecular analyses and links to the Sequence Read Archive of selected samples from the Tara Oceans Expedition (2009-2013) [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875581, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_SEQUENCING_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875581 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 19) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;% \n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_low_thresh = 10,\n                size_high_thresh = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875581_', stringr::str_pad(15:24, side = \"left\", pad = \"0\", width = 3)))\n\n# save for later\nreadr::write_rds(PANGAEA_875581, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875581.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875567",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875567",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.3 Carbonate chemistry (PANGAEA.875567)",
    "text": "3.3 Carbonate chemistry (PANGAEA.875567)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875567\nCitation:\n\nGuidi, Lionel; Gattuso, Jean-Pierre; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about carbonate chemistry in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875567, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_ENV-DEPTH-CARB_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875567 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 21) %&gt;% \n  # for setting column types. For some reason I can't maket his work within readxl\n  # https://github.com/tidyverse/readxl/issues/198\n  mutate(across(19:last_col(), as.numeric)) %&gt;% \n  mutate(across(19:last_col(), ~ifelse(is.nan(.), NA, .))) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;%\n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_low_thresh = 10,\n                size_high_thresh = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875567_', str_pad(15:68, side = \"left\", pad = \"0\", width = 3)))\n\n# save for later\nreadr::write_rds(PANGAEA_875567, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875567.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875575",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875575",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.4 Nutrient concentrations (PANGAEA.875575)",
    "text": "3.4 Nutrient concentrations (PANGAEA.875575)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875575\nCitation:\n\nGuidi, Lionel; Morin, Pascal; Coppola, Laurent; Tremblay, Jean-Éric; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about nutrients in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875575, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_ENV-DEPTH-NUT_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875575 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 21)  %&gt;% \n  # for setting column types. For some reason I can't maket his work within readxl\n  # https://github.com/tidyverse/readxl/issues/198\n  mutate(across(19:last_col(), as.numeric)) %&gt;% \n  mutate(across(19:last_col(), ~ifelse(is.nan(.), NA, .))) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;%\n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_low_thresh = 10,\n                size_high_thresh = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875575_', str_pad(15:38, side = \"left\", pad = \"0\", width = 3)))\n\n# save for later\nreadr::write_rds(PANGAEA_875575, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875575.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875569",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875569",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.5 Pigment concentrations (PANGAEA.875569)",
    "text": "3.5 Pigment concentrations (PANGAEA.875569)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875569\nCitation:\n\nGuidi, Lionel; Ras, Josephine; Claustre, Hervé; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about pigment concentrations (HPLC) in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875569, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# extrac to temporary directory\narchive::archive_extract(\n  \"https://store.pangaea.de/Projects/TARA-OCEANS/Samples_Registry/TARA_SAMPLES_CONTEXT_ENV-DEPTH-HPLC_20170515.zip\",\n  dir = tmpdir,\n  files = NULL,\n  options = character(),\n  strip_components = 0L\n)\n\nPANGAEA_875569 &lt;- readxl::read_excel(fs::dir_ls(tmpdir), skip = 21) %&gt;% \n  # for setting column types. For some reason I can't maket his work within readxl\n  # https://github.com/tidyverse/readxl/issues/198\n  mutate(across(19:last_col(), as.numeric)) %&gt;% \n  mutate(across(19:last_col(), ~ifelse(is.nan(.), NA, .))) %&gt;% \n  dplyr::select(-1) %&gt;% \n  dplyr::slice(-1) %&gt;% \n  mutate(across(7:9, as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_station = 4,\n                tara_event = 5, \n                env_ontology = 6,\n                depth = 7,\n                depth_min = 8,\n                depth_max = 9,\n                size_low_thresh = 10,\n                size_high_thresh = 11,\n                tara_id01 = 12,\n                tara_id02 = 13,\n                tara_id03 = 14) %&gt;% \n  dplyr::rename_with(.cols = 15:last_col(), ~ stringr::str_c('PANGAEA.875569_', str_pad(15:143, side = \"left\", pad = \"0\", width = 3)))\n\n# save for later\nreadr::write_rds(PANGAEA_875569, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875569.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::dir_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875576",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875576",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.6 Sensor data (PANGAEA.875576)",
    "text": "3.6 Sensor data (PANGAEA.875576)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875576\nCitation:\n\nGuidi, Lionel; Picheral, Marc; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about sensor data in the targeted environmental feature [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875576, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# download the file\ndownload.file(\"https://doi.pangaea.de/10.1594/PANGAEA.875576?format=textfile\", \n              tmpdir, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\n# this is annoying. The pangeae text files have a bunch of metadata headers between the characters\n#/* */ and but I couldn't immediately think of a way to parse a that in readr so I just grepped \"*/\"\n# which basically means we must read the file twice and take the performance hit. Also this may be \n# brittle in a way that I can't anticipate right now\nskipline &lt;- grep('\\\\*/', readLines(tmpdir))\n\nPANGAEA_875576 &lt;- read_tsv(tmpdir, skip = skipline) %&gt;% \n  mutate(across(13:15, as.numeric)) %&gt;% \n  mutate(across(24:last_col(), as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_basis = 4, \n                tara_campaign = 5, \n                tara_station = 6,\n                sampling_device = 7, \n                tara_event = 8, \n                date_time = 9,\n                latitude = 10,\n                longitude = 11,\n                env_ontology = 12,\n                depth = 13,\n                depth_min = 14, \n                depth_max = 15,\n                size_low_thresh = 16,\n                size_high_thresh = 17,\n                tara_id01 = 18,\n                tara_id02 = 19,\n                tara_id03 = 20) %&gt;%\n  mutate(date_time = lubridate::ymd_hms(date_time)) %&gt;% \n  dplyr::rename_with(.cols = 21:last_col(), ~ stringr::str_c('PANGAEA.875576_', str_pad(21:147, side = \"left\", pad = \"0\", width = 3)))\n\n# save the data for reuse\nreadr::write_rds(PANGAEA_875576, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875576.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::file_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875577",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875577",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.7 Derived mesoscale features (PANGAEA.875577)",
    "text": "3.7 Derived mesoscale features (PANGAEA.875577)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875577\nCitation:\n\nArdyna, Mathieu; d’Ovidio, Francesco; Speich, Sabrina; Leconte, Jade; Chaffron, Samuel; Audic, Stephane; Garczarek, Laurence; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about mesoscale features at the sampling location [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875577, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\nNote most of these features seem to be derived from model or satellite data and do not represent in situ measurements.\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# download the file\ndownload.file(\"https://doi.pangaea.de/10.1594/PANGAEA.875577?format=textfile\", \n              tmpdir, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\n# this is annoying. The pangeae text files have a bunch of metadata headers between the characters\n#/* */ and but I couldn't immediately think of a way to parse a that in readr so I just grepped \"*/\"\n# which basically means we must read the file twice and take the performance hit. Also this may be \n# brittle in a way that I can't anticipate right now\nskipline &lt;- grep('\\\\*/', readLines(tmpdir))\n\nPANGAEA_875577 &lt;- read_tsv(tmpdir, skip = skipline) %&gt;% \n  mutate(across(13:15, as.numeric)) %&gt;% \n  mutate(across(24:last_col(), as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_basis = 4, \n                tara_campaign = 5, \n                tara_station = 6,\n                sampling_device = 7, \n                tara_event = 8, \n                date_time = 9,\n                latitude = 10,\n                longitude = 11,\n                env_ontology = 12,\n                depth = 13,\n                depth_min = 14,\n                depth_max = 15,\n                size_low_thresh = 16,\n                size_high_thresh = 17,\n                tara_id01 = 18,\n                tara_id02 = 19,\n                tara_id03 = 20) %&gt;%\n  mutate(date_time = lubridate::ymd_hms(date_time)) %&gt;% \n  dplyr::rename_with(.cols = 21:last_col(), ~ stringr::str_c('PANGAEA.875577_', str_pad(21:71, side = \"left\", pad = \"0\", width = 3)))\n\n# save the data for reuse\nreadr::write_rds(PANGAEA_875577, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875577.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::file_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875579",
    "href": "R/tara/02_download_data_pangaea.html#sec-PANGAEA.875579",
    "title": "Download environmental data from Pangaea.de",
    "section": "3.8 Whole water column features (PANGAEA.875579)",
    "text": "3.8 Whole water column features (PANGAEA.875579)\nSource URL: https://doi.pangaea.de/10.1594/PANGAEA.875579\nCitation:\n\nSpeich, Sabrina; Chaffron, Samuel; Ardyna, Mathieu; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Environmental context of all samples from the Tara Oceans Expedition (2009-2013), about the water column features at the sampling location [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.875579, In: Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Registry of all samples from the Tara Oceans Expedition (2009-2013) [dataset publication series]. PANGAEA, https://doi.org/10.1594/PANGAEA.875582\n\nThese features seem to contain information about specific features in the water column like the DCM, primary nitrite maximum, and the depth of the O2 minimum.\n\n\nShow/hide code\n# create temporary location to decompress\ntmpdir &lt;- fs::file_temp()\n\n# download the file\ndownload.file(\"https://doi.pangaea.de/10.1594/PANGAEA.875579?format=textfile\", \n              tmpdir, \n              \"curl\", quiet = FALSE, mode = \"w\",\n              cacheOK = TRUE,\n              extra = getOption(\"download.file.extra\"),\n              headers = NULL)\n\n# this is annoying. The Pangaea text files have a bunch of metadata headers between the characters\n#/* */ and but I couldn't immediately think of a way to parse a that in readr so I just grepped \"*/\"\n# which basically means we must read the file twice and take the performance hit. Also this may be \n# brittle in a way that I can't anticipate right now\nskipline &lt;- grep('\\\\*/', readLines(tmpdir))\n\nPANGAEA_875579 &lt;- read_tsv(tmpdir, skip = skipline) %&gt;% \n  mutate(across(13:15, as.numeric)) %&gt;% \n  mutate(across(33:last_col(), as.numeric)) %&gt;% \n  dplyr::rename(tara_barcode_num = 1,\n                biosample_acc_num = 2,\n                ena_acc_num = 3, \n                tara_basis = 4, \n                tara_campaign = 5, \n                tara_station = 6,\n                sampling_device = 7, \n                tara_event = 8, \n                date_time = 9,\n                latitude = 10,\n                longitude = 11,\n                env_ontology = 12,\n                depth = 13,\n                depth_min = 14,\n                depth_max = 15,\n                size_low_thresh = 16,\n                size_high_thresh = 17,\n                tara_id01 = 18,\n                tara_id02 = 19,\n                tara_id03 = 20) %&gt;%\n  mutate(date_time = lubridate::ymd_hms(date_time)) %&gt;% \n  dplyr::rename_with(.cols = 21:last_col(), ~ stringr::str_c('PANGAEA.875579_', str_pad(21:123, side = \"left\", pad = \"0\", width = 3)))\n\n# save the data for reuse\nreadr::write_rds(PANGAEA_875579, here::here(\"_data_raw\", \"tara\", \"PANGAEA_875579.rds\"), compress = \"xz\", compression = 9L)\n\n# Remove decompressed coverage directory from temp location\nfs::file_delete(tmpdir)",
    "crumbs": [
      "1. Tara oceans workflow",
      "2) Env data at Pangaea.de"
    ]
  },
  {
    "objectID": "index.html#project-organization",
    "href": "index.html#project-organization",
    "title": "Retrieve, format, and impute environmental data associated with marine ’omics data sets",
    "section": "",
    "text": "We follow the convention that only raw, unmodified, unfiltered, and non-subsetted datafiles obtained directly from database sources (including journal article metadata) are placed in the _data_raw directory. These should never be modified or changed. All data derived from these _data_raw files (including modification, filtering, and subsetting) are placed in the data directory"
  },
  {
    "objectID": "R/tara/03_download_darwin.html",
    "href": "R/tara/03_download_darwin.html",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "",
    "text": "This code loads required libraries and sets global variables\n\n\nShow/hide code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(here)\nlibrary(arrow)",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#api-authorization-to-cmap-sql-database",
    "href": "R/tara/03_download_darwin.html#api-authorization-to-cmap-sql-database",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "2.1 API authorization to CMAP SQL database",
    "text": "2.1 API authorization to CMAP SQL database\nThe api key is stored locally (not git tracked) in _notrack/cmap_api.txt\n\n\nShow/hide code\nlibrary(cmap4r)\ncmap4r::set_authorization(reset = TRUE)\ncmap4r::set_authorization(cmap_key = \"\")",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#simons-cmap-catalog",
    "href": "R/tara/03_download_darwin.html#simons-cmap-catalog",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "2.2 Simons CMAP catalog",
    "text": "2.2 Simons CMAP catalog\nDownload a local copy of the CMAP catalog. Useful for querying later…\n\n\nShow/hide code\nlocal_cat &lt;- cmap4r::get_catalog() %&gt;%\n  select(Variable, Table_Name, Unit, Sensor, Unit)\n\nwrite_tsv(local_cat, here::here(\"_data_raw\", \"cmap\", \"cmap_catalog.tsv\"))\n\n\nhttp://darwinproject.mit.edu/\n\n“The Darwin Project is an initiative to advance the development and application of novel models of marine microbes and microbial communities, identifying the relationships of individuals and communities to their environment, connecting cellular-scale processes to global microbial community structure.”\n\n\n\nShow/hide code\nlocal_cat %&gt;% \n  filter(stringr::str_detect(Table_Name, \"(?i)darwin\")) %&gt;% \n  distinct(Table_Name)",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_nutrient",
    "href": "R/tara/03_download_darwin.html#tbldarwin_nutrient",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "4.1 tblDarwin_Nutrient",
    "text": "4.1 tblDarwin_Nutrient\nSource: https://simonscmap.com/catalog/datasets/Darwin_Nutrient\n\n4.1.1 Download full query range\n\n\nShow/hide code\ntara_tblDarwin_Nutrient &lt;- tara2darwin_nest %&gt;%\n  dplyr::mutate(tbl = purrr::map(\n    dw_query,\n    purrr::slowly(\n      function(df)\n        cmap4r::get_spacetime(\n          tableName = 'tblDarwin_Nutrient',\n          varName = '*',\n          dt1 = as.character(df$dt1),\n          dt2 = as.character(df$dt2),\n          lat1 = df$lat1,\n          lat2 = df$lat2,\n          lon1 = df$lon1,\n          lon2 = df$lon2\n        ),\n      rate = rate_delay(3),\n      quiet = TRUE\n    ),\n    .progress = TRUE\n  ))\n\ntara_tblDarwin_Nutrient %&gt;% \n  unnest(c(tbl, dw_query)) %&gt;%\n  dplyr::rename(depth_dw = depth, lat_dw=lat, lon_dw=lon, time_dw=time) %&gt;% \n  dplyr::relocate(tara_station, lat_dw, lon_dw, depth_dw, time_dw) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Nutrient_subset.parquet\"))\n\n\n\n\n4.1.2 Filter to closest Tara matches\nFiltering Darwin output to only closest matching time, distance, and depth. Difference in times are computed using lubridate package. Distance between two coordinate sets is calculated by the Haversine distance implemented by geosphere::distHaversine. Distance between depths is calculated as a simple difference.\nThere are two special considerations:\n\nSome Tara stations are close to land and picking grid points with minimum Haversine distance to the Tara coordinates will end up selecting positions on land. We include a filtering criteria to exclude all Tara grid points that contain only NA values for DIN/PO4/SiOH4 for all depths.\nTara station TARA_209 is located off of Greenland on the shelf. The sampling depth for the mesopelagic samples is listed as 351 meters. However, in Pangaea datasets the bathymetry depth for this coordinate set is 215 meters. In Darwin (and PISCES) there are no observations at 351 meters, so we instead choose the minimum depth difference between 351 meters and the model depth level with a DIN/PO4/SiOH4 value/.\n\n\n\nShow/hide code\ntblDarwin_Nutrient_subset_filt &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Nutrient_subset.parquet\")) %&gt;% \n  dplyr::mutate(time_dw = lubridate::as_date(stringr::str_extract(time_dw, \"^\\\\d{4}-\\\\d{2}-\\\\d{2}\"))) %&gt;% \n  # calculate difference in date between darwin and Tara\n  dplyr::mutate(tdiff = abs(time_dw - date_time)) %&gt;% \n  dplyr::group_by(tara_station, latitude, longitude, date_time) %&gt;% \n  # filter to include only darwin time points with smallest time difference to Tara observation \n  dplyr::filter(tdiff == min(tdiff)) %&gt;% \n  dplyr::ungroup() %&gt;% \n  # remove Darwin grid coords that only contain NA values for DIN (these are either on land or ice)\n  dplyr::group_by(tara_station, lat_dw, lon_dw, time_dw) %&gt;% \n  dplyr::filter(sum(is.na(DIN)) != n()) %&gt;% \n  dplyr::ungroup() %&gt;% \n  dplyr::rowwise() %&gt;% \n  # calculate Haversine distance (in meters) betwen darwin coord set and Tara coord set\n  dplyr::mutate(ddiff = geosphere::distHaversine(c(longitude, latitude), c(lon_dw, lat_dw))) %&gt;% \n  dplyr::group_by(tara_station, latitude, longitude, date_time) %&gt;% \n  # filter to include only darwin grid point with smallest Haversine distance\n  dplyr::filter(ddiff == min(ddiff)) %&gt;% \n  dplyr::ungroup() %&gt;% \n  # join back to the full dataset that includes depths for Tara samples. We expect a many2many relationship\n  dplyr::left_join(tara2darwin,\n                  by = join_by(tara_station, latitude, longitude, date_time, lat1, lat2, lon1, lon2, dt1, dt2),\n                  relationship = \"many-to-many\") %&gt;% \n  # calculate difference in magnitude between darwin depth and Tara observation\n  dplyr::mutate(dpdiff = abs(depth_dw - depth)) %&gt;% \n  # filter to only consider Darwin grid points with DIN observations\n  dplyr::filter(!is.na(DIN)) %&gt;% \n  dplyr::group_by(tara_station, latitude, longitude, date_time, depth) %&gt;% \n  # filter to include only smallest depth difference\n  dplyr::filter(dpdiff == min(dpdiff)) %&gt;% \n  dplyr::ungroup() %&gt;% \n  dplyr::group_by(tara_station, latitude, longitude, date_time, depth) %&gt;% \n  # Some observations have multiple equal depth differences (e.g., target depth is 50 and nearest \n  # Darwin depths are 45 and 55) this ensures we only take one of them\n  dplyr::filter(depth_dw == min(depth_dw)) %&gt;% \n  dplyr::ungroup() %&gt;% \n  # recording the difference between Darwin grid point and Tara coords, difference between depths and times\n  dplyr::mutate(tdiff = lubridate::make_difftime(tdiff, units = \"hours\"),\n                ddiff = ddiff/1000) %&gt;% \n  dplyr::rename(time_diff_hr = tdiff, dist_diff_km = ddiff, depth_diff_m = dpdiff ) %&gt;% \n  # some formatting and cleaning\n  dplyr::relocate(tara_barcode_num, tara_station:longitude, depth, date_time, \n                  lat_dw, lon_dw, depth_dw, time_dw, dist_diff_km, depth_diff_m, time_diff_hr) %&gt;% \n  dplyr::select(-(lat1:dt2)) \n\n# write output for later\narrow::write_parquet(tblDarwin_Nutrient_subset_filt, here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Nutrient_subset_filt.parquet\"))\n\n\n\n\n4.1.3 Save closest Darwin grid coords\nWrite 0.25 degree resolved coordinates for later access to Darwin without needing a 1 degree range. It is faster to use exact coords in the API\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- tblDarwin_Nutrient_subset_filt %&gt;% \n  dplyr::select(tara_station:time_diff_hr) %&gt;% \n  distinct() \n\narrow::write_parquet(darwin_tara_grid_map, here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\n\n\n\n4.1.4 Save closest PISCES grid coords\nWrite 0.25 degree resolved coordinates for later access to PISCES. We’ll use these in the next notebook\n\n\nShow/hide code\ntblDarwin_Nutrient_subset_filt %&gt;% \n  # the only reason I know to set this to 200 is by looking at PISCES output from this grid coords and seeing that \n  # the maximum depth was 199 meters\n  mutate(depth = if_else(tara_station == \"TARA_209\" & depth == 351, 200, depth)) %&gt;% \n  dplyr::select(tara_station, lat_cm=lat_dw, latitude, lon_cm=lon_dw, longitude, depth, date_time, dist_diff_km) %&gt;% \n  distinct() %&gt;% \n  readr::write_csv(here::here(\"data\", \"tara\", \"pisces_subsets\", \"pisces_tara_grid_map.csv\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_ecosystem",
    "href": "R/tara/03_download_darwin.html#tbldarwin_ecosystem",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "4.2 tblDarwin_Ecosystem",
    "text": "4.2 tblDarwin_Ecosystem\nSource: https://simonscmap.com/catalog/datasets/Darwin_Ecosystem\nNow we can use the exact coordinates and dates in our SQL queries to CMAP so that we reduce the amount of data needed to transfer. This version of the variable tara2darwin_nest has the best mapping (i.e. smallest Haversine distance) between the Tara coordinate and the grid in MIT Darwin.\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\ntara2darwin_nest &lt;- darwin_tara_grid_map %&gt;%\n  dplyr::select(tara_station, lat_dw, lon_dw, time_dw) %&gt;% \n  distinct() %&gt;% \n  tidyr::nest(dw_query = -tara_station)\n\n\n\n4.2.1 Download\n\n\nShow/hide code\ntara_tblDarwin_Ecosystem &lt;- tara2darwin_nest %&gt;%\n  dplyr::mutate(tbl = purrr::map(\n    dw_query,\n    purrr::slowly(\n      function(df)\n        cmap4r::get_spacetime(\n          tableName = 'tblDarwin_Ecosystem',\n          varName = '*',\n          dt1 = as.character(df$time_dw),\n          dt2 = as.character(df$time_dw),\n          lat1 = df$lat_dw,\n          lat2 = df$lat_dw,\n          lon1 = df$lon_dw,\n          lon2 = df$lon_dw\n        ),\n      # using a 3 second rate delay between calls\n      rate = rate_delay(3),\n      quiet = TRUE\n    ),\n    .progress = TRUE\n  ))\n\ntara_tblDarwin_Ecosystem %&gt;% \n  unnest(c(tbl)) %&gt;% \n  dplyr::rename(time_dw = time, lat_dw = lat, lon_dw = lon, depth_dw = depth) %&gt;% \n  dplyr::select(-dw_query) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Ecosystem_subset.parquet\"))\n\n\n\n\n4.2.2 Filtering\nFiltering Darwin output to only closest matching depth. Distance between depths is calculated as a simple difference.\n\n\nShow/hide code\nleft_join(darwin_tara_grid_map,\n          arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Ecosystem_subset.parquet\")),\n          by = join_by(tara_station, lat_dw, lon_dw, depth_dw, time_dw)) %&gt;% \n  dplyr::left_join(tara2darwin, by = join_by(tara_station, latitude, longitude, depth, date_time)) %&gt;% \n  dplyr::relocate(tara_barcode_num, tara_station, latitude, longitude, depth, date_time, lat_dw, lon_dw, depth_dw, time_dw) %&gt;% \n  dplyr::select(-dist_diff_km, -depth_diff_m, -time_diff_hr, -lat1, -lat2, -lon1, -lon2, -dt1, -dt2) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Ecosystem_subset_filt.parquet\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_ocean_color",
    "href": "R/tara/03_download_darwin.html#tbldarwin_ocean_color",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "4.3 tblDarwin_Ocean_Color",
    "text": "4.3 tblDarwin_Ocean_Color\nSource: https://simonscmap.com/catalog/datasets/Darwin_Ocean_Color\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\ntara2darwin_nest &lt;- darwin_tara_grid_map %&gt;%\n  dplyr::select(tara_station, lat_dw, lon_dw, time_dw) %&gt;% \n  distinct() %&gt;% \n  tidyr::nest(dw_query = -tara_station)\n\n\n\n4.3.1 Download\n\n\nShow/hide code\ntara_tblDarwin_Ocean_Color &lt;- tara2darwin_nest %&gt;%\n  dplyr::mutate(tbl = purrr::map(\n    dw_query,\n    purrr::slowly(\n      function(df)\n        cmap4r::get_spacetime(\n          tableName = 'tblDarwin_Ocean_Color',\n          varName = '*',\n          dt1 = as.character(df$time_dw),\n          dt2 = as.character(df$time_dw),\n          lat1 = df$lat_dw,\n          lat2 = df$lat_dw,\n          lon1 = df$lon_dw,\n          lon2 = df$lon_dw\n        ),\n      rate = rate_delay(3),\n      quiet = TRUE\n    ),\n    .progress = TRUE\n  ))\n\ntara_tblDarwin_Ocean_Color %&gt;%\n  unnest(c(tbl)) %&gt;% \n  dplyr::rename(time_dw = time, lat_dw = lat, lon_dw = lon, depth_dw = depth) %&gt;% \n  dplyr::select(-dw_query) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Ocean_Color_subset.parquet\"))\n\n\n\n\n4.3.2 Filtering\nFiltering Darwin output to only closest matching depth. Distance between depths is calculated as a simple difference.\n\n\nShow/hide code\nleft_join(darwin_tara_grid_map,\n          arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Ocean_Color_subset.parquet\")),\n          by = join_by(tara_station, lat_dw, lon_dw, depth_dw, time_dw)) %&gt;% \n  dplyr::left_join(tara2darwin, by = join_by(tara_station, latitude, longitude, depth, date_time)) %&gt;% \n  dplyr::relocate(tara_barcode_num, tara_station, latitude, longitude, depth, date_time, lat_dw, lon_dw, depth_dw, time_dw) %&gt;% \n  dplyr::select(-dist_diff_km, -depth_diff_m, -time_diff_hr, -lat1, -lat2, -lon1, -lon2, -dt1, -dt2) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Ocean_Color_subset_filt.parquet\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_phytoplankton",
    "href": "R/tara/03_download_darwin.html#tbldarwin_phytoplankton",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "4.4 tblDarwin_Phytoplankton",
    "text": "4.4 tblDarwin_Phytoplankton\nSource: https://simonscmap.com/catalog/datasets/Darwin_Phytoplankton\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\ntara2darwin_nest &lt;- darwin_tara_grid_map %&gt;%\n  dplyr::select(tara_station, lat_dw, lon_dw, time_dw) %&gt;% \n  distinct() %&gt;% \n  tidyr::nest(dw_query = -tara_station)\n\n\n\n4.4.1 Download\n\n\nShow/hide code\ntara_tblDarwin_Phytoplankton &lt;- tara2darwin_nest %&gt;%\n  dplyr::mutate(tbl = purrr::map(\n    dw_query,\n    purrr::slowly(\n      function(df)\n        cmap4r::get_spacetime(\n          tableName = 'tblDarwin_Phytoplankton',\n          varName = '*',\n          dt1 = as.character(df$time_dw),\n          dt2 = as.character(df$time_dw),\n          lat1 = df$lat_dw,\n          lat2 = df$lat_dw,\n          lon1 = df$lon_dw,\n          lon2 = df$lon_dw\n        ),\n      rate = rate_delay(3),\n      quiet = TRUE\n    ),\n    .progress = TRUE\n  ))\n\ntara_tblDarwin_Phytoplankton %&gt;% \n  unnest(c(tbl)) %&gt;% \n  dplyr::rename(time_dw = time, lat_dw = lat, lon_dw = lon, depth_dw = depth) %&gt;% \n  dplyr::select(-dw_query) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Phytoplankton_subset.parquet\"))\n\n\n\n\n4.4.2 Filtering\nFiltering Darwin output to only closest matching depth. Distance between depths is calculated as a simple difference.\n\n\nShow/hide code\nleft_join(darwin_tara_grid_map,\n          arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Phytoplankton_subset.parquet\")),\n          by = join_by(tara_station, lat_dw, lon_dw, depth_dw, time_dw)) %&gt;% \n  dplyr::left_join(tara2darwin, by = join_by(tara_station, latitude, longitude, depth, date_time)) %&gt;% \n  dplyr::relocate(tara_barcode_num, tara_station, latitude, longitude, depth, date_time, lat_dw, lon_dw, depth_dw, time_dw) %&gt;% \n  dplyr::select(-dist_diff_km, -depth_diff_m, -time_diff_hr, -lat1, -lat2, -lon1, -lon2, -dt1, -dt2) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Phytoplankton_subset_filt.parquet\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_nutrient_climatology",
    "href": "R/tara/03_download_darwin.html#tbldarwin_nutrient_climatology",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "5.1 tblDarwin_Nutrient_Climatology",
    "text": "5.1 tblDarwin_Nutrient_Climatology\nSource: https://simonscmap.com/catalog/datasets/Darwin-MITgcm_Climatology\n\n5.1.1 Download\n\n\nShow/hide code\ntblDarwin_Nutrient_Climatology &lt;- cmap4r::get_spacetime(\n  tableName = \"tblDarwin_Nutrient_Climatology\",\n  varName = \"*\",\n  dt1 = \"\",\n  dt2 = \"\",\n  lat1 = -90,\n  lat2 = 90,\n  lon1 = -180,\n  lon2 = 180\n)\n\ntblDarwin_Nutrient_Climatology %&gt;% \n  dplyr::rename(lat_dw = lat, lon_dw = lon, depth_dw = depth) %&gt;% \n  arrow::write_parquet(here::here(\"_data_raw\", \"cmap\", \"darwin\", \"tblDarwin_Nutrient_Climatology.parquet\"))\n\n\n\n\n5.1.2 Filtering\nFiltering Darwin output to only closest matching depth. We use the “Tara to Darwin grid mapping” derived earlier. Distance between depths is calculated as the magnitude of their difference.\nSomething seriously weird is happening - I should be able to join on depth_dw variable in both datasets but for some cases NAs are produced when there is not missing data in the Darwin climatology data. Note issue here on joining by numbers. Apparently better to convert to string first?\nNote: also something weird going on with TARA_206 at depth 411. In the 3-day average Darwin model these values are not missing, but they are missing in the climatology\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\nleft_join(darwin_tara_grid_map,\n          arrow::read_parquet(here::here(\"_data_raw\", \"cmap\", \"darwin\", \"tblDarwin_Nutrient_Climatology.parquet\")),\n          by = join_by(lat_dw, lon_dw),\n          relationship = \"many-to-many\") %&gt;%\n  group_by(tara_station, lat_dw, lon_dw, depth_dw.x) %&gt;% \n  filter(abs(depth_dw.x-depth_dw.y) == min(abs(depth_dw.x-depth_dw.y))) %&gt;% \n  ungroup() %&gt;% \n  dplyr::left_join(tara2darwin, by = join_by(tara_station, latitude, longitude, depth, date_time)) %&gt;% \n  dplyr::relocate(tara_barcode_num, tara_station, latitude, longitude, depth, date_time, lat_dw, lon_dw, depth_dw.x, time_dw) %&gt;%\n  dplyr::rename(depth_dw = depth_dw.x) %&gt;% \n  dplyr::select(-dist_diff_km, -depth_diff_m, -time_diff_hr, -lat1, -lat2, -lon1, -lon2, -dt1, -dt2) %&gt;% \n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Nutrient_Climatology_subset_filt.parquet\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_plankton_climatology",
    "href": "R/tara/03_download_darwin.html#tbldarwin_plankton_climatology",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "5.2 tblDarwin_Plankton_Climatology",
    "text": "5.2 tblDarwin_Plankton_Climatology\nSource: https://simonscmap.com/catalog/datasets/Darwin-MITgcm_Climatology\n\n5.2.1 Download\n\n\nShow/hide code\ntblDarwin_Plankton_Climatology &lt;- cmap4r::get_spacetime(\n  tableName = \"tblDarwin_Plankton_Climatology\",\n  varName = \"*\",\n  dt1 = \"\",\n  dt2 = \"\",\n  lat1 = -90,\n  lat2 = 90,\n  lon1 = -180,\n  lon2 = 180\n)\n\ntblDarwin_Plankton_Climatology %&gt;% \n  dplyr::rename(lat_dw = lat, lon_dw = lon, depth_dw = depth) %&gt;% \n  arrow::write_parquet(here::here(\"_data_raw\", \"cmap\", \"darwin\", \"tblDarwin_Plankton_Climatology.parquet\"))\n\n\n\n\n5.2.2 Filtering\nFiltering Darwin output to only closest matching depth. We use the “Tara to Darwin grid mapping” derived earlier. Distance between depths is calculated as the magnitude of their difference.\nSomething seriously weird is happening - I should be able to join on depth_dw variable in both datasets but for some cases NAs are produced when there is not missing data in the Darwin climatology data. Note issue here on joining by numbers. Apparently better to convert to string first?\nNote: also something weird going on with TARA_206 at depth 411. In the 3-day average Darwin model these values are not missing, but they are missing in the climatology\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\nleft_join(darwin_tara_grid_map,\n          arrow::read_parquet(here::here(\"_data_raw\", \"cmap\", \"darwin\", \"tblDarwin_Plankton_Climatology.parquet\")),\n          by = join_by(lat_dw, lon_dw),\n          relationship = \"many-to-many\") %&gt;%\n  group_by(tara_station, lat_dw, lon_dw, depth_dw.x) %&gt;% \n  filter(abs(depth_dw.x-depth_dw.y) == min(abs(depth_dw.x-depth_dw.y))) %&gt;% \n  ungroup() %&gt;% \n  dplyr::left_join(tara2darwin, by = join_by(tara_station, latitude, longitude, depth, date_time)) %&gt;% \n  dplyr::relocate(tara_barcode_num, tara_station, latitude, longitude, depth, date_time, lat_dw, lon_dw, depth_dw.x, time_dw) %&gt;%\n  dplyr::rename(depth_dw = depth_dw.x) %&gt;% \n  dplyr::select(-dist_diff_km, -depth_diff_m, -time_diff_hr, -lat1, -lat2, -lon1, -lon2, -dt1, -dt2) %&gt;% \n  #filter(if_any(everything(), ~is.na(.)))\n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Plankton_Climatology_subset_filt.parquet\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/tara/03_download_darwin.html#tbldarwin_chl_climatology",
    "href": "R/tara/03_download_darwin.html#tbldarwin_chl_climatology",
    "title": "Download Darwin Biogeochemical model output from Simons CMAP",
    "section": "5.3 tblDarwin_Chl_Climatology",
    "text": "5.3 tblDarwin_Chl_Climatology\nSource: https://simonscmap.com/catalog/datasets/Darwin-MITgcm_Climatology\n\n5.3.1 Download\n\n\nShow/hide code\ntblDarwin_Chl_Climatology &lt;- cmap4r::get_spacetime(\n  tableName = \"tblDarwin_Chl_Climatology\",\n  varName = \"*\",\n  dt1 = \"\",\n  dt2 = \"\",\n  lat1 = -90,\n  lat2 = 90,\n  lon1 = -180,\n  lon2 = 180\n)\n\ntblDarwin_Chl_Climatology %&gt;% \n  dplyr::rename(lat_dw = lat, lon_dw = lon, depth_dw = depth) %&gt;% \n  arrow::write_parquet(here::here(\"_data_raw\", \"cmap\", \"darwin\", \"tblDarwin_Chl_Climatology.parquet\"))\n\n\n\n\n5.3.2 Filtering\nFiltering Darwin output to only closest matching depth. We use the “Tara to Darwin grid mapping” derived earlier. Distance between depths is calculated as the magnitude of their difference.\nSomething seriously weird is happening - I should be able to join on depth_dw variable in both datasets but for some cases NAs are produced when there is not missing data in the Darwin climatology data. Note issue here on joining by numbers. Apparently better to convert to string first?\nNote: also something weird going on with TARA_206 at depth 411. In the 3-day average Darwin model these values are not missing, but they are missing in the climatology\n\n\nShow/hide code\ndarwin_tara_grid_map &lt;- arrow::read_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"darwin_tara_grid_map.parquet\"))\n\nleft_join(darwin_tara_grid_map,\n          arrow::read_parquet(here::here(\"_data_raw\", \"cmap\", \"darwin\", \"tblDarwin_Chl_Climatology.parquet\")),\n          by = join_by(lat_dw, lon_dw),\n          relationship = \"many-to-many\") %&gt;%\n  group_by(tara_station, lat_dw, lon_dw, depth_dw.x) %&gt;% \n  filter(abs(depth_dw.x-depth_dw.y) == min(abs(depth_dw.x-depth_dw.y))) %&gt;% \n  ungroup() %&gt;% \n  dplyr::left_join(tara2darwin, by = join_by(tara_station, latitude, longitude, depth, date_time)) %&gt;% \n  dplyr::relocate(tara_barcode_num, tara_station, latitude, longitude, depth, date_time, lat_dw, lon_dw, depth_dw.x, time_dw) %&gt;%\n  dplyr::rename(depth_dw = depth_dw.x) %&gt;% \n  dplyr::select(-dist_diff_km, -depth_diff_m, -time_diff_hr, -lat1, -lat2, -lon1, -lon2, -dt1, -dt2) %&gt;% \n  #filter(if_any(everything(), ~is.na(.)))\n  arrow::write_parquet(here::here(\"data\", \"tara\", \"darwin_subsets\", \"tblDarwin_Chl_Climatology_subset_filt.parquet\"))",
    "crumbs": [
      "1. Tara oceans workflow",
      "3) Darwin model output"
    ]
  },
  {
    "objectID": "R/biogeotraces/01_download_idp2021.html",
    "href": "R/biogeotraces/01_download_idp2021.html",
    "title": "Download GEOTRACES IDP 2021v2 from Simons CMAP",
    "section": "",
    "text": "This code loads required libraries and sets global variables\n\n\nShow/hide code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(here)\nlibrary(cmap4r)\nlibrary(arrow)\nlibrary(sf)\nlibrary(polars)",
    "crumbs": [
      "2. BioGEOTRACES workflow",
      "1) IDP 2021 v2 at Simons CMAP"
    ]
  },
  {
    "objectID": "R/biogeotraces/01_download_idp2021.html#api-authorization-to-cmap-sql-database",
    "href": "R/biogeotraces/01_download_idp2021.html#api-authorization-to-cmap-sql-database",
    "title": "Download GEOTRACES IDP 2021v2 from Simons CMAP",
    "section": "2.1 API authorization to CMAP SQL database",
    "text": "2.1 API authorization to CMAP SQL database\nThe api key is stored locally (not git tracked) in _notrack/cmap_api.txt\n\n\nShow/hide code\ncmap4r::set_authorization(reset = TRUE)\ncmap4r::set_authorization(cmap_key = \"\")",
    "crumbs": [
      "2. BioGEOTRACES workflow",
      "1) IDP 2021 v2 at Simons CMAP"
    ]
  },
  {
    "objectID": "R/biogeotraces/01_download_idp2021.html#simons-cmap-catalog",
    "href": "R/biogeotraces/01_download_idp2021.html#simons-cmap-catalog",
    "title": "Download GEOTRACES IDP 2021v2 from Simons CMAP",
    "section": "2.2 Simons CMAP catalog",
    "text": "2.2 Simons CMAP catalog\nDownload a local copy of the CMAP catalog. Useful for querying later…\n\n\nShow/hide code\nlocal_cat &lt;- cmap4r::get_catalog() %&gt;%\n  select(Variable, Table_Name, Unit, Sensor, Unit)\n\nwrite_tsv(local_cat, here::here(\"_data_raw\", \"cmap\", \"cmap_catalog.tsv\"))",
    "crumbs": [
      "2. BioGEOTRACES workflow",
      "1) IDP 2021 v2 at Simons CMAP"
    ]
  },
  {
    "objectID": "R/biogeotraces/01_download_idp2021.html#cmap-catalog",
    "href": "R/biogeotraces/01_download_idp2021.html#cmap-catalog",
    "title": "Download GEOTRACES IDP 2021v2 from Simons CMAP",
    "section": "3.1 CMAP catalog",
    "text": "3.1 CMAP catalog\nLots of variables associated with these datasets\n\n\nShow/hide code\nlocal_cat %&gt;%\n  filter(Table_Name %in% c(\"tblGeotraces_Sensor\", \"tblGeotraces_Seawater_IDP2021v2\"))",
    "crumbs": [
      "2. BioGEOTRACES workflow",
      "1) IDP 2021 v2 at Simons CMAP"
    ]
  },
  {
    "objectID": "R/biogeotraces/01_download_idp2021.html#geotraces-sensor-data",
    "href": "R/biogeotraces/01_download_idp2021.html#geotraces-sensor-data",
    "title": "Download GEOTRACES IDP 2021v2 from Simons CMAP",
    "section": "3.2 GEOTRACES sensor data",
    "text": "3.2 GEOTRACES sensor data\nHere we are just downloading the entire dataset and not restricting by time, depth, or coordinates\n\n\nShow/hide code\ngt_sens &lt;- cmap4r::get_spacetime(\n  tableName = \"tblGeotraces_Sensor\",\n  varName = \"*\",\n  dt1 = \"2006-07-13\",\n  dt2 = \"2018-11-22\",\n  lat1 = -90,\n  lat2 = 90,\n  lon1 = -180,\n  lon2 = 180\n)\n\narrow::write_parquet(gt_sens, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Sensor.parquet\"))",
    "crumbs": [
      "2. BioGEOTRACES workflow",
      "1) IDP 2021 v2 at Simons CMAP"
    ]
  },
  {
    "objectID": "R/biogeotraces/01_download_idp2021.html#geotraces-seawater-chemical-measurements",
    "href": "R/biogeotraces/01_download_idp2021.html#geotraces-seawater-chemical-measurements",
    "title": "Download GEOTRACES IDP 2021v2 from Simons CMAP",
    "section": "3.3 GEOTRACES seawater chemical measurements",
    "text": "3.3 GEOTRACES seawater chemical measurements\nAgain, we are just downloading the entire dataset and not restricting by time, depth, or coordinates\n\n\nShow/hide code\ntarget_vars &lt;- local_cat %&gt;% \n  dplyr::filter(Table_Name == \"tblGeotraces_Seawater_IDP2021v2\") %&gt;%\n  tibble::rownames_to_column() %&gt;% \n  pull(Variable)\n\n\nThere seems to be a limit to the number of variables you can request at once (about 300 from what I can tell). Therefore, we will need to access this data in 300 column chunks. Also you cannot specify multiple variables using the get_spacetime() function so we have to write a manual SQL query\n\n\nShow/hide code\ntarget_vars_split &lt;- split(target_vars[45:length(target_vars)], ceiling(seq_along(target_vars[45:length(target_vars)])/200))\n\n\nSet up the manual SQL query\n\n\nShow/hide code\ntarget_queries_split &lt;- map(target_vars_split, \\(x) paste0(\"SELECT [time], lat, lon, \", paste(c(target_vars[1:45], x), collapse = ', '), \" FROM tblGeotraces_Seawater_IDP2021v2 WHERE [time] BETWEEN '2006-07-13' AND '2018-11-22' AND lat BETWEEN -90 AND 90 AND lon BETWEEN -180 AND 180\"))\n\n\nPerform the SQL query to Simons CMAP remote. Once we get these data frames then we write them locally as Apache Arrow parquet format\n\n\nShow/hide code\ngt_sw_01 &lt;-  cmap4r::exec_manualquery(target_queries_split[[1]])\narrow::write_parquet(gt_sw_01, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part01.parquet\"))\n\ngt_sw_02 &lt;-  cmap4r::exec_manualquery(target_queries_split[[2]])\narrow::write_parquet(gt_sw_02, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part02.parquet\"))\n\ngt_sw_03 &lt;-  cmap4r::exec_manualquery(target_queries_split[[3]])\narrow::write_parquet(gt_sw_03, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part03.parquet\"))\n\ngt_sw_04 &lt;-  cmap4r::exec_manualquery(target_queries_split[[4]])\narrow::write_parquet(gt_sw_04, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part04.parquet\"))\n\ngt_sw_05 &lt;-  cmap4r::exec_manualquery(target_queries_split[[5]])\narrow::write_parquet(gt_sw_05, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part05.parquet\"))\n\ngt_sw_06 &lt;-  cmap4r::exec_manualquery(target_queries_split[[6]])\narrow::write_parquet(gt_sw_06, here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part06.parquet\"))\n\n\nNow we want to combine these datasets back together into a single object that we can save and use later. Basically we need to do a bunch of chained left_joins. We will use the polars library R api for this because it is fast.\n\n\nShow/hide code\njoincols &lt;- c(\"time\", \"lat\", \"lon\", \"N_SAMPLES\", \"N_STATIONS\", \"cruise_id\",\n              \"station_id\", \"station_type\", \"Bot__Depth\",\n              \"Operator_s_Cruise_Name\", \"Ship_Name\", \"Period\",\n              \"Chief_Scientist\", \"GEOTRACES_Scientist\", \"Cruise_Aliases\",\n              \"Cruise_Information_Link\", \"BODC_Cruise_Number\",\n              \"CTDPRS_T_VALUE_SENSOR\", \"CTDPRS_T_VALUE_SENSOR_qc\",\n              \"DEPTH_SENSOR\", \"DEPTH_SENSOR_qc\", \"Rosette_Bottle_Number\",\n              \"Rosette_Bottle_Number_qc\", \"GEOTRACES_Sample_ID\",\n              \"GEOTRACES_Sample_ID_qc\", \"Bottle_Flag\", \"Bottle_Flag_qc\",\n              \"Cast_Identifier\", \"Cast_Identifier_qc\", \"Sampling_Device\",\n              \"Sampling_Device_qc\", \"BODC_Bottle_Number\",\n              \"BODC_Bottle_Number_qc\", \"BODC_Event_Number\",\n              \"BODC_Event_Number_qc\", \"Single_Cell_ID\", \"Single_Cell_ID_qc\",\n              \"NCBI_Single_Cell_Genome_BioProject_Accession\",\n              \"NCBI_Single_Cell_Genome_BioProject_Accession_qc\")\n\ndropcols &lt;- c(\"NCBI_Metagenome_BioSample_Accession\",\n              \"NCBI_Metagenome_BioSample_Accession_qc\",\n              \"NCBI_16S_18S_rRNA_gene_BioSample_Accession\",\n              \"NCBI_16S_18S_rRNA_gene_BioSample_Accession_qc\",\n              \"EMBL_EBI_Metagenome_MGNIFY_Analysis_Accession\",\n              \"EMBL_EBI_Metagenome_MGNIFY_Analysis_Accession_qc\", \n              \"CTDTMP_T_VALUE_SENSOR\", \n              \"CTDTMP_T_VALUE_SENSOR_qc\", \n              \"CTDSAL_D_CONC_SENSOR\")\n\n\n\n\nShow/hide code\ngt_sw_01 &lt;- pl$scan_parquet(here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part01.parquet\"))\ngt_sw_02 &lt;- pl$scan_parquet(here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part02.parquet\"))\ngt_sw_03 &lt;- pl$scan_parquet(here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part03.parquet\"))\ngt_sw_04 &lt;- pl$scan_parquet(here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part04.parquet\"))\ngt_sw_05 &lt;- pl$scan_parquet(here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part05.parquet\"))\ngt_sw_06 &lt;- pl$scan_parquet(here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2-part06.parquet\"))\n\n# now using polars syntax\ngt_sw &lt;- gt_sw_01$join(\n  gt_sw_02,\n  on = joincols,\n  how = \"left\"\n)$drop(dropcols)$join(\n  gt_sw_03,\n  on = joincols,\n  how = \"left\"\n)$drop(dropcols)$join(\n  gt_sw_04,\n  on = joincols,\n  how = \"left\"\n)$drop(dropcols)$join(\n  gt_sw_05,\n  on = joincols,\n  how = \"left\"\n)$drop(dropcols)$join(\n  gt_sw_06,\n  on = joincols,\n  how = \"left\"\n)$collect()\n\n# write the final combined data set in parquet format\narrow::write_parquet(as.data.frame(gt_sw), \n                     here::here(\"_data_raw\", \"cmap\", \"geotraces\", \"tblGeotraces_Seawater_IDP2021v2.parquet\"))",
    "crumbs": [
      "2. BioGEOTRACES workflow",
      "1) IDP 2021 v2 at Simons CMAP"
    ]
  },
  {
    "objectID": "R/tara/04_download_pisces.html",
    "href": "R/tara/04_download_pisces.html",
    "title": "Download PISCES Biogeochemical model hindcast",
    "section": "",
    "text": "Here we download the hindcast ouput from the PISCES biogeochemical model corresponding to Tara Ocean samples. We use the Copernicus Marine Toolbox python API with a tsv file containing the query coordinates as input (generated in a prior step) to download individual netcdf files for each coordinate query set.\nAn alternative approach is to follow this strategy where a Copernicus Marine data source is loaded as an xarray dataset using ‘lazy-loading’ mode. However, I found that opening the dataset remotely with lazy-loading was very slow. Subsetting the datset remotely, then downloading the subsetted product was much faster, albeit more clunky.\nNote: you need to register with Copernicus Marine Data to use this resource.\n\n\nWe will download all variables from the Global Ocean Biogeochemistry Hindcast for the grid point and time nearest to each Tara Oceans sample. After download these will be saved as a csv for later use.\n\nProduct: GLOBAL_MULTIYEAR_BGC_001_029\n\nDataset: cmems_mod_glo_bgc_my_0.25deg_P1M-m\n\n\nThe biogeochemical hindcast for global ocean is produced at Mercator-Ocean (Toulouse. France). It provides 3D biogeochemical fields since year 1993 at 1/4 degree and on 75 vertical levels. It uses PISCES biogeochemical model (available on the NEMO modelling platform). No data assimilation in this product.\nLatest NEMO version (v3.6_STABLE) - Forcings: FREEGLORYS2V4 ocean physics produced at Mercator-Ocean and ERA-Interim atmosphere produced at ECMWF at a daily frequency - Outputs: Daily (chlorophyll. nitrate. phosphate. silicate. dissolved oxygen. primary production) and monthly (chlorophyll. nitrate. phosphate. silicate. dissolved oxygen. primary production. iron. phytoplankton in carbon) 3D mean fields interpolated on a standard regular grid in NetCDF format. The simulation is performed once and for all. - Initial conditions: World Ocean Atlas 2013 for nitrate. phosphate. silicate and dissolved oxygen. &gt; GLODAPv2 for DIC and Alkalinity. and climatological model outputs for Iron and DOC - Quality/Accuracy/Calibration information: See the related QuID - DOI (product): https://doi.org/10.48670/moi-00019",
    "crumbs": [
      "1. Tara oceans workflow",
      "4) PISCES model output"
    ]
  },
  {
    "objectID": "R/tara/04_download_pisces.html#global-ocean-biogeochemistry-hindcast",
    "href": "R/tara/04_download_pisces.html#global-ocean-biogeochemistry-hindcast",
    "title": "Download PISCES Biogeochemical model hindcast",
    "section": "",
    "text": "We will download all variables from the Global Ocean Biogeochemistry Hindcast for the grid point and time nearest to each Tara Oceans sample. After download these will be saved as a csv for later use.\n\nProduct: GLOBAL_MULTIYEAR_BGC_001_029\n\nDataset: cmems_mod_glo_bgc_my_0.25deg_P1M-m\n\n\nThe biogeochemical hindcast for global ocean is produced at Mercator-Ocean (Toulouse. France). It provides 3D biogeochemical fields since year 1993 at 1/4 degree and on 75 vertical levels. It uses PISCES biogeochemical model (available on the NEMO modelling platform). No data assimilation in this product.\nLatest NEMO version (v3.6_STABLE) - Forcings: FREEGLORYS2V4 ocean physics produced at Mercator-Ocean and ERA-Interim atmosphere produced at ECMWF at a daily frequency - Outputs: Daily (chlorophyll. nitrate. phosphate. silicate. dissolved oxygen. primary production) and monthly (chlorophyll. nitrate. phosphate. silicate. dissolved oxygen. primary production. iron. phytoplankton in carbon) 3D mean fields interpolated on a standard regular grid in NetCDF format. The simulation is performed once and for all. - Initial conditions: World Ocean Atlas 2013 for nitrate. phosphate. silicate and dissolved oxygen. &gt; GLODAPv2 for DIC and Alkalinity. and climatological model outputs for Iron and DOC - Quality/Accuracy/Calibration information: See the related QuID - DOI (product): https://doi.org/10.48670/moi-00019",
    "crumbs": [
      "1. Tara oceans workflow",
      "4) PISCES model output"
    ]
  },
  {
    "objectID": "R/tara/04_download_pisces.html#functions",
    "href": "R/tara/04_download_pisces.html#functions",
    "title": "Download PISCES Biogeochemical model hindcast",
    "section": "2.1 Functions",
    "text": "2.1 Functions\n\n\nShow/hide code\ndef get_project_root():\n    \"\"\"\n    Determines the root directory of the project by searching for specific markers.\n\n    The function searches for the presence of a `.venv`, `renv`, or `.git` directory\n    in the current working directory and its parent directories. The first directory\n    containing any of these markers is considered the project root.\n\n    Returns:\n      pathlib.Path: The path to the project root directory if found, otherwise None.\n    \"\"\"\n    current_path = pathlib.Path(os.getcwd())\n    for path in [current_path, *current_path.parents]:\n        if (path / \".venv\").exists() or (path / \"renv\").exists() or (path / \".git\").exists():\n            return path\n    return None\n\n\ndef get_filename_without_extension(file_path):\n  \"\"\"\n  Extracts the filename without the extension from a given file path.\n\n  Args:\n    file_path: The path to the file.\n\n  Returns:\n    The filename without the extension.\n  \"\"\"\n  filename = os.path.basename(file_path)\n  name_without_extension, _ = os.path.splitext(filename)\n  return name_without_extension\n\n\ndef read_netcdfs(files, dim):\n    def process_one_path(path):\n        \"\"\"\n        Processes a single file path to an xarray dataset.\n\n        This function reads an xarray dataset from the given file path, assigns a new \n        value to the dataset which is the basename of the file (without extension), \n        and loads all data from the transformed dataset to ensure it can be used \n        after closing the original file.\n\n        Parameters:\n        path (str): The file path to the xarray dataset.\n\n        Returns:\n        xarray.Dataset: The processed xarray dataset with the new 'query_id' attribute.\n        \"\"\"\n        # use a context manager, to ensure the file gets closed after use\n        with xr.open_dataset(path) as ds:\n            # assign new value which is basename of the file that was read\n            ds = ds.assign(query_id=get_filename_without_extension(path))\n            # load all data from the transformed dataset, to ensure we can\n            # use it after closing each original file\n            ds.load()\n            return ds\n\n    paths = sorted(files)\n    datasets = [process_one_path(p) for p in paths]\n    combined = xr.concat(datasets, dim, coords='minimal')\n    return combined",
    "crumbs": [
      "1. Tara oceans workflow",
      "4) PISCES model output"
    ]
  },
  {
    "objectID": "R/tara/04_download_pisces.html#work-environment",
    "href": "R/tara/04_download_pisces.html#work-environment",
    "title": "Download PISCES Biogeochemical model hindcast",
    "section": "5.1 Work environment",
    "text": "5.1 Work environment\n\n\nShow/hide code\nimport session_info\nsession_info.show()\n\n\n\nClick to view session information\n-----\ncopernicusmarine    2.0.0\npandas              2.2.3\nsession_info        1.0.0\nxarray              2025.1.2\n-----\n\n\nClick to view modules imported as dependencies\nannotated_types     0.7.0\nasciitree           NA\nasttokens           NA\nbackports           NA\nboto3               1.36.16\nbotocore            1.36.16\ncertifi             2025.01.31\ncharset_normalizer  3.4.1\nclick               8.1.8\ncloudpickle         3.1.1\ncomm                0.2.2\ncython_runtime      NA\ndask                2025.1.0\ndateutil            2.9.0.post0\ndebugpy             1.8.12\ndecorator           5.1.1\nexceptiongroup      1.2.2\nexecuting           2.2.0\nfsspec              2025.2.0\nh5netcdf            1.5.0\nh5py                3.12.1\nidna                3.10\nimportlib_metadata  NA\nipykernel           6.29.5\njaraco              NA\njedi                0.19.2\njmespath            1.0.1\nlxml                5.3.0\nmore_itertools      10.3.0\nnumcodecs           0.13.1\nnumpy               2.2.2\npackaging           24.2\nparso               0.8.4\npkg_resources       NA\nplatformdirs        4.3.6\nprompt_toolkit      3.0.50\npsutil              6.1.1\npure_eval           0.2.3\npydantic            2.10.6\npydantic_core       2.27.2\npydev_ipython       NA\npydevconsole        NA\npydevd              3.2.3\npydevd_file_utils   NA\npydevd_plugins      NA\npydevd_tracing      NA\npygments            2.19.1\npystac              1.12.1\npytz                2025.1\nrequests            2.32.3\ns3transfer          0.11.2\nsemver              3.0.4\nsitecustomize       NA\nsix                 1.17.0\nstack_data          0.6.3\ntlz                 1.0.0\ntoolz               1.0.0\ntornado             6.4.2\ntqdm                4.67.1\ntraitlets           5.14.3\ntyping_extensions   NA\nurllib3             2.3.0\nvscode              NA\nwcwidth             0.2.13\nyaml                6.0.2\nzarr                2.18.3\nzipp                NA\nzmq                 26.2.1\nzoneinfo            NA\n\n \n-----\nIPython             8.32.0\njupyter_client      8.6.3\njupyter_core        5.7.2\n-----\nPython 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\nLinux-6.9.3-76060903-generic-x86_64-with-glibc2.35\n-----\nSession information updated at 2025-02-08 23:52",
    "crumbs": [
      "1. Tara oceans workflow",
      "4) PISCES model output"
    ]
  }
]